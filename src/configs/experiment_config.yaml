---
experiment:
  root_name: 4eedi
pipeline:
  dataset: x
  crossvalidator: nested
  predictor: x
  preprocessor: x
  inprocessor: x
  postprocessor: x
crossvalidation:
  nfolds: 10
  parameters_gridsearch: exhaustive # combinations or exhaustive
  paramgrid:
    x: 
      - x
predictors:
  early_stopping: False
  lstm:
    cell_type: GRU
    n_layers: 1
    n_cells: 
      - 16
    dropout: 0.02
    optimiser: adam
    loss: cce
    batch_size: 16
    verbose: -1
    padding_value: 0
    early_stopping: False
    save_best_model: True
    patience: 5
    shuffle: False
    epochs: 50
  decision_tree:
    max_depth: null
  garf:
    n_estimators: 5
    max_depth: 5
    population_size: 10
    generations: 10
  smotennrf:
    n_estimators: 500
    max_depth: 15
  sssvc:
    kernel: linear
    C: 0.001
  lr:
    penalty: l2
    C: 100
    solver: liblinear
preprocessors:
  rebalance:
    index: 3
    dummy: 5
  luong:
    k: 3
  alabdulmohsin:
    sgd_steps: 10 # 10000
    full_gradient_epochs: 1 #100
    max_admm_iter: 1 #100
  zemel:
    k: 3
  lahoti:
    k: 3
    max_iter: 1000
  lahoti2:
    k: 3 # latent dimension
    max_iter: 1000
  zehlike:
    thetas: 0.1
  chawla:
    k: 5
    sampling_strategy: minority
  calders:
    sampling_proportions: 1
  yan:
    clustering: kmeans
    knn: 5
  celis:
    sampling_factor: 1.25
  li:
    C_factor: 10
    fairness_metric: dp
  salazar:
    oversampling_factor: 2
    safe_weight: 1
    borderline_weight: 1
    rare_weight: 0.7
  dablain:
    proportion: 1
    k: 5
  zelaya:
    d: -0.3
  singh: 
    k: 5
  jiang:
    unfair_metric: tp
    population_size: 100
    max_gen: 50
  cock:
    clustering: spectral
    combinations:
      - 2
      - 3
      - 4
      - 5
      - 6
      - 7
      - 8
      - 9
      - 10
postprocessors:
  pleiss:
    alpha: 0.2
    lambda: 10
  awasthi:
    perturbation_type: 1 # 0, 2, 3
  kamiran:
    low_threshold: 0.01
    high_threshold: 0.99
    num_ROC_margin: 50
    metric_ub: 0.05
    metric_lb: -0.05
    num_class_thresholds: 100
  nguyen:
      noise_gp_lower: 0.00005
      noise_gp_upper: 0.5
      budget: 5
  snel:
    traag: ja
inprocessors:
  schreuder:
    alpha: 0.5
    perc_unlab: 0.2
    shuffle: True
  iosifidis:
    n_estimators: 200
    trade_off_c: 0.1
  li: 
    C: 0.0001
    max_iter: 100
  fish:
    model: lr
  alghamdi:
    model: logit
    tolerance: 0.01
    constraint: meo
    enem: 20000 #20000, 50000, 100000, 200000, 500000, 1000000, 1400000
  chai:
    min_range: 1
    max_range: 20
    n_steps: 10
  kilbertus:
    optimiser: unconstrained # 'lagrange', 'iplb', 'projected', 'lagrange_fixed_lambda'
    epochs: 10
    batchsize: 64
  chakraborty:
    goals: ABCD
  wang:
    constraint: 0.05
    alpha: 0.1
  gao:
    grl_lambda: 50
    epochs: 10
    batch_size: 128
  islam:
    hidden_layers: # 64, 64, 64 / 32, 32, 32
      - 64
      - 32
      - 16
    mini_batch_size: 128 # 256
    learning_rate: 0.001 # 0.005
    drop_probs: 0 # 0.5
    activations: rectify # leaky
    weight_decays: 0 # 1e-5
    n_pretrain_epochs: 1
    n_epochs: 1
    a_func: leaky
    lambda: 1
    drop_probs: 0
  li:
    epochs: 0
    batch_size: 256
  sikdar:
    model_name: log-reg
    metric_name: stpr
    hidden_size: 30
    layers: 2
  zhang:
    epochs: 100
  grari2:
    n_estimators: 100
    learning_rate: 0.05
    max_depth: 3
    max_features: 0.9
    min_impurity_decrease: 0
    min_impurity_split: None
    min_samples_leaf: 2
    min_samples_split: 2
    min_weight_fraction_leaf: 0
    presort: 0
    lambda: 0.1
  chen:
    model_name: lr # svm rf
  zafar:
    C: 0.01
    kernel: linear
  oneto:
    whatdoballerinaswear: twoto
  chuang:
    epochs: 50
    optimising: eo # dp
    method: mixup
    lambda: 0.5
  mary:
    epochs: 1
    lr: 0.00001
  zhao: 
    premodel: LR # MLP or SVM
  romano:
    batch_size: 32
    learning_rate: 0.5
    steps: 1
    mu_val: 0.99999
    second_scale: 0.01
    epochs: 50
    model_type: linear_model
    pretrain_epochs: 20
    dis_epochs: 30
    epochs: 30
  do:
    re: mi
  liu:
      batch_size: 128
      epochs: 50
...