{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T19:41:21.909039Z",
     "iopub.status.busy": "2025-07-19T19:41:21.908721Z",
     "iopub.status.idle": "2025-07-19T19:41:21.916571Z",
     "shell.execute_reply": "2025-07-19T19:41:21.915944Z",
     "shell.execute_reply.started": "2025-07-19T19:41:21.909016Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-19 23:17:22.472586: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "seaborn not found, pip install seaborn to use plots functions\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Predictors \n",
    "from debiased.predictors.decision_tree import DTClassifier\n",
    "from debiased.predictors.logistic_regression import LogisticRegressionClassifier\n",
    "from debiased.predictors.oulad_smotenn import SmoteENNRFBoostClassifier\n",
    "from debiased.predictors.portugal_garf import GARFClassifier\n",
    "from debiased.predictors.xuetangx_svc import StandardScalingSVCClassifier\n",
    "\n",
    "# Pre-Processing\n",
    "from debiased.mitigation.preprocessing.alabdulmohsin import AlabdulmohsinPreProcessor\n",
    "from debiased.mitigation.preprocessing.calders import CaldersPreProcessor\n",
    "from debiased.mitigation.preprocessing.chakraborty import ChakrabortyPreProcessor\n",
    "from debiased.mitigation.preprocessing.cock import CockPreProcessor\n",
    "from debiased.mitigation.preprocessing.dablain import DablainPreProcessor\n",
    "from debiased.mitigation.preprocessing.iosifidis_resampledattribute import IosifidisResamplingAttributePreProcessor\n",
    "from debiased.mitigation.preprocessing.iosifidis_resampletarget import IosifidisResamplingTargetPreProcessor\n",
    "from debiased.mitigation.preprocessing.iosifidis_smoteattribute import IosifidisSmoteAttributePreProcessor\n",
    "from debiased.mitigation.preprocessing.iosifidis_smotetarget import IosifidisSmoteTargetPreProcessor\n",
    "from debiased.mitigation.preprocessing.lahoti import LahotiPreProcessor\n",
    "from debiased.mitigation.preprocessing.li import LiPreProcessor\n",
    "from debiased.mitigation.preprocessing.zelaya_over import ZelayaOverPreProcessor\n",
    "from debiased.mitigation.preprocessing.zelaya_smote import ZelayaSMOTEPreProcessor\n",
    "from debiased.mitigation.preprocessing.zelaya_over import ZelayaOverPreProcessor\n",
    "from debiased.mitigation.preprocessing.zemel import ZemelPreProcessor\n",
    "\n",
    "# In-Processing\n",
    "from debiased.mitigation.inprocessing.chakraborty_in import ChakrabortyInProcessor\n",
    "from debiased.mitigation.inprocessing.chen import ChenInProcessor\n",
    "from debiased.mitigation.inprocessing.gao import GaoInProcessor\n",
    "from debiased.mitigation.inprocessing.grari2 import Grari2InProcessor\n",
    "from debiased.mitigation.inprocessing.islam import IslamInProcessor\n",
    "from debiased.mitigation.inprocessing.kilbertus import KilbertusInProcessor\n",
    "from debiased.mitigation.inprocessing.liu import LiuInProcessor\n",
    "from debiased.mitigation.inprocessing.zafar import ZafarInProcessor\n",
    "\n",
    "# Post Processing\n",
    "from debiased.mitigation.postprocessing.kamiranpost import KamiranPostProcessor\n",
    "from debiased.mitigation.postprocessing.pleiss import PleissPostProcessor\n",
    "from debiased.mitigation.postprocessing.snel import SnelPostProcessor\n",
    "\n",
    "# Scorer\n",
    "from debiased.crossvalidation.scorers.binary_scorer import BinaryClfScorer\n",
    "from debiased.crossvalidation.scorers.fairness_binary_scorer import BinaryFairnessScorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Here is a script to transform the datasets we gave you into features, targets, and demographic lists. \n",
    "To load your own dataset, skip the following cell, and move on to the next one! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T19:39:31.565330Z",
     "iopub.status.busy": "2025-07-19T19:39:31.565150Z",
     "iopub.status.idle": "2025-07-19T19:39:31.572371Z",
     "shell.execute_reply": "2025-07-19T19:39:31.571797Z",
     "shell.execute_reply.started": "2025-07-19T19:39:31.565312Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "dataset_path = '../data/student-performance-math/data_dictionary.pkl'\n",
    "with open(dataset_path, 'rb') as fp:\n",
    "    dataset = pickle.load(fp)\n",
    "\n",
    "# Format dataset\n",
    "lids = [lid for lid in dataset['data']]\n",
    "features = [\n",
    "    dataset['data'][lid]['features'] for lid in lids\n",
    "]\n",
    "labels = [\n",
    "    dataset['data'][lid]['binary_label'] for lid in lids\n",
    "]\n",
    "demographics = [\n",
    "    {'sex': dataset['data'][lid]['sex'], 'famsize': dataset['data'][lid]['famsize']} for lid in lids\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T19:39:31.579382Z",
     "iopub.status.busy": "2025-07-19T19:39:31.579004Z",
     "iopub.status.idle": "2025-07-19T19:39:31.582744Z",
     "shell.execute_reply": "2025-07-19T19:39:31.582134Z",
     "shell.execute_reply.started": "2025-07-19T19:39:31.579363Z"
    }
   },
   "outputs": [],
   "source": [
    "mitigating_attributes = 'sex.famsize'\n",
    "mitigating_scores = ['sex', 'famsize']\n",
    "discriminated = '_0_1._0_0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To integrate your own dataset, create one list for the:\n",
    "- features (one list per student)\n",
    "- labels (one integer per student)\n",
    "- demographics (one dictionary with all demographic attributes as values, and the demographic as key per student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T12:56:37.745023Z",
     "iopub.status.busy": "2025-07-19T12:56:37.744748Z",
     "iopub.status.idle": "2025-07-19T12:56:37.749341Z",
     "shell.execute_reply": "2025-07-19T12:56:37.748481Z",
     "shell.execute_reply.started": "2025-07-19T12:56:37.745004Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = ''\n",
    "dataset = # read function\n",
    "features = [\n",
    "    # one list per student\n",
    "]\n",
    "labels = [\n",
    "    # one integer/float per student\n",
    "]\n",
    "demographics = [\n",
    "    # one dictionary per student\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T13:44:46.899063Z",
     "iopub.status.busy": "2025-07-19T13:44:46.898748Z",
     "iopub.status.idle": "2025-07-19T13:44:50.778224Z",
     "shell.execute_reply": "2025-07-19T13:44:50.777025Z",
     "shell.execute_reply.started": "2025-07-19T13:44:46.899037Z"
    }
   },
   "source": [
    "# Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have already implemented a few base predictors which were implemented for open-source educationnal datasets that you can use:**\n",
    "- ```DTClassifier```\n",
    "    - decision tree\n",
    "- ```LogisticRegressionClassifier```\n",
    "    - eedi\n",
    "    - logistic regression\n",
    "- ```SmoteENNRFBoostClassifier```\n",
    "    - oulad\n",
    "    - smote to rebalance the classes + RF\n",
    "- ```GARFClassifier```\n",
    "    - portuguese datasets\n",
    "    - genetic algorithm for best set + RF\n",
    "- ```StandardScalingSVCClassifier```\n",
    "    - xuetangx\n",
    "    - scaling followed by a classifier\n",
    "\n",
    "\n",
    "  \n",
    "**You can call the following functions on those 5 classifiers:**\n",
    "- ```fit(x_train, y_train, xval (can be an empty list), yval (can be an empty list))```: trains the classifier\n",
    "- ```predict(features)```: returns the predicted class\n",
    "\n",
    "- ```predict_proba(features)```: returns the probability of the instance belonging to each class according to the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T19:39:31.585306Z",
     "iopub.status.busy": "2025-07-19T19:39:31.585073Z",
     "iopub.status.idle": "2025-07-19T19:39:41.712256Z",
     "shell.execute_reply": "2025-07-19T19:39:41.711137Z",
     "shell.execute_reply.started": "2025-07-19T19:39:31.585286Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_dt = DTClassifier(max_depth=5)\n",
    "clf_dt.fit(features[:275], labels[:275])\n",
    "\n",
    "clf_lr = LogisticRegressionClassifier(penalty='l2', C=100, solver='liblinear')\n",
    "clf_lr.fit(features[:275], labels[:275])\n",
    "\n",
    "clf_smoterf = SmoteENNRFBoostClassifier(n_estimators=500, max_depth=15)\n",
    "clf_smoterf.fit(features[:275], labels[:275])\n",
    "\n",
    "clf_garf = GARFClassifier()\n",
    "clf_garf.fit(features[:275], labels[:275])\n",
    "\n",
    "clf_svc = StandardScalingSVCClassifier(kernel='linear', C=0.001)\n",
    "clf_svc.fit(features[:275], labels[:275])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T19:39:41.713664Z",
     "iopub.status.busy": "2025-07-19T19:39:41.713253Z",
     "iopub.status.idle": "2025-07-19T19:39:41.792705Z",
     "shell.execute_reply": "2025-07-19T19:39:41.792055Z",
     "shell.execute_reply.started": "2025-07-19T19:39:41.713633Z"
    }
   },
   "outputs": [],
   "source": [
    "dt_pred = clf_dt.predict(features[275:])\n",
    "lr_pred = clf_lr.predict(features[275:])\n",
    "smoterf_pred = clf_smoterf.predict(features[275:])\n",
    "garf_pred = clf_garf.predict(features[275:])\n",
    "svc_pred = clf_svc.predict(features[275:])\n",
    "\n",
    "dt_proba = clf_dt.predict_proba(features[275:])\n",
    "lr_proba = clf_lr.predict_proba(features[275:])\n",
    "smoterf_proba = clf_smoterf.predict_proba(features[275:])\n",
    "garf_proba = clf_garf.predict_proba(features[275:])\n",
    "svc_proba = clf_svc.predict_proba(features[275:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add your own classifier here! \n",
    "\n",
    "For compatibility with: \n",
    "- *pre-processing* methods, your classifier needs to:\n",
    "    - be able to receive the features and ground truths as input (as the usual convention)\n",
    "- *in-processing* methods, your classifier needs to:\n",
    "    - the in-processing predictor will fully replace your predictor\n",
    "- *post-processing* methods, your classifier needs to:\n",
    "    - output the raw predictions (probabilities) for each instance of the test set\n",
    "    - output the predicted class for each instance of the test set (can be inferred from the raw predictions)\n",
    "    - output the demographic attribute of each instance (this should normally be possible from the data, without passing through the predictor, unless your predictor re-arranges the order of its predictions)\n",
    "    - the ground truth for each instance (this should normally be possible from the data, without passing through the predictor, unless your predictor re-arranges the order of its predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T14:17:21.914700Z",
     "iopub.status.busy": "2025-07-19T14:17:21.914432Z",
     "iopub.status.idle": "2025-07-19T14:17:22.345641Z",
     "shell.execute_reply": "2025-07-19T14:17:22.343464Z",
     "shell.execute_reply.started": "2025-07-19T14:17:21.914679Z"
    }
   },
   "outputs": [],
   "source": [
    "your_predictor = xxx\n",
    "your_predictor.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores per group for the SVC: {0: 0.6465028355387523, 1: 0.5846267553584626, 'all': 0.6118861607142857}\n"
     ]
    }
   ],
   "source": [
    "fairness = BinaryFairnessScorer(mitigating_scores, discriminated, np.unique(labels))\n",
    "scores = fairness.get_fairness_scores(labels[275:], svc_pred, svc_proba, demographics[275:])\n",
    "print('scores per group for the SVC:', scores['sex']['roc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMM Iteration 0: \t  0050100%\n",
      "primal residual:  1.5837910935312212\n",
      "dual residual:  17.287620977652185 \n",
      "\n",
      "395 instances were massaged! (100.0%)\n"
     ]
    }
   ],
   "source": [
    "pre_processor = AlabdulmohsinPreProcessor(mitigating_attributes, discriminated)\n",
    "new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "pre_processor = CaldersPreProcessor(mitigating_attributes, discriminated)\n",
    "new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = ChakrabortyPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = CockPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = ZelayaOverPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = DablainPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = ZelayaOverPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = IosifidisResamplingAttributePreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = ZelayaOverPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = IosifidisResamplingTargetPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = IosifidisSmoteAttributePreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = IosifidisSmoteTargetPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = LahotiPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = IosifidisSmoteTargetPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = LahotiPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = LiPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = ZelayaOverPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = ZelayaSMOTEPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# pre_processor = ZemelPreProcessor(mitigating_attributes, discriminated)\n",
    "# new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores per group for the SVC: {0: 0.6465028355387523, 1: 0.5846267553584626, 'all': 0.6118861607142857}\n",
      "scores per group for the preprocessed with Calders SVC: {0: 0.717391304347826, 1: 0.6921655580192165, 'all': 0.7004743303571429}\n",
      "ADMM Iteration 0: \t  0050100%\n",
      "primal residual:  1.5703455127470975\n",
      "dual residual:  17.28701487350002 \n",
      "\n",
      "395 instances were massaged! (100.0%)\n",
      "scores per group for the pre-processed with Alabdulmohsin SVC: {0: 0.6370510396975425, 1: 0.5809312638580931, 'all': 0.6018415178571429}\n"
     ]
    }
   ],
   "source": [
    "pre_processor = CaldersPreProcessor(mitigating_attributes, discriminated)\n",
    "new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# clf_svc = StandardScalingSVCClassifier(kernel='linear', C=0.001)\n",
    "clf_svc = GARFClassifier()\n",
    "_ = clf_svc.fit(new_x[:275], new_y[:275])\n",
    "pre_svc_pred = clf_svc.predict(features[275:])\n",
    "pre_svc_proba = clf_svc.predict_proba(features[275:])\n",
    "\n",
    "fairness = BinaryFairnessScorer(mitigating_scores, discriminated, np.unique(labels))\n",
    "pre_scores = fairness.get_fairness_scores(labels[275:], pre_svc_pred, pre_svc_proba, demographics[275:])\n",
    "print('scores per group for the SVC:', scores['sex']['roc'])\n",
    "print('scores per group for the preprocessed with Calders SVC:', pre_scores['sex']['roc'])\n",
    "\n",
    "pre_processor = AlabdulmohsinPreProcessor(mitigating_attributes, discriminated)\n",
    "new_x, new_y, new_demo = pre_processor.fit_transform(features, labels, demographics)\n",
    "\n",
    "# clf_svc = StandardScalingSVCClassifier(kernel='linear', C=0.001)\n",
    "clf_svc = GARFClassifier()\n",
    "_ = clf_svc.fit(new_x[:275], new_y[:275])\n",
    "pre_svc_pred = clf_svc.predict(features[275:])\n",
    "pre_svc_proba = clf_svc.predict_proba(features[275:])\n",
    "\n",
    "fairness = BinaryFairnessScorer(mitigating_scores, discriminated, np.unique(labels))\n",
    "prealabd_scores = fairness.get_fairness_scores(labels[275:], pre_svc_pred, pre_svc_proba, demographics[275:])\n",
    "print('scores per group for the pre-processed with Alabdulmohsin SVC:', prealabd_scores['sex']['roc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T16:17:17.883229Z",
     "iopub.status.busy": "2025-07-19T16:17:17.882950Z",
     "iopub.status.idle": "2025-07-19T16:17:19.333206Z",
     "shell.execute_reply": "2025-07-19T16:17:19.331765Z",
     "shell.execute_reply.started": "2025-07-19T16:17:17.883208Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/cock/anaconda3/envs/debiased/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "in_processor = ChakrabortyInProcessor(mitigating_attributes, discriminated)\n",
    "in_processor.fit(features[:275], labels[:275], demographics[:275])\n",
    "\n",
    "# in_processor = ChenInProcessor(mitigating_attributes, discriminated)\n",
    "# in_processor.fit(features[:275], labels[:275], demographics[:275])\n",
    "\n",
    "# in_processor = GaoInProcessor(mitigating_attributes, discriminated)\n",
    "# in_processor.fit(features[:275], labels[:275], demographics[:275])\n",
    "\n",
    "# in_processor = Grari2InProcessor(mitigating_attributes, discriminated)\n",
    "# in_processor.fit(features[:275], labels[:275], demographics[:275])\n",
    "\n",
    "# in_processor = IslamInProcessor(mitigating_attributes, discriminated)\n",
    "# in_processor.fit(features[:275], labels[:275], demographics[:275])\n",
    "\n",
    "# in_processor = KilbertusInProcessor(mitigating_attributes, discriminated)\n",
    "# in_processor.fit(features[:275], labels[:275], demographics[:275])\n",
    "\n",
    "# in_processor = LiuInProcessor(mitigating_attributes, discriminated)\n",
    "# in_processor.fit(features[:275], labels[:275], demographics[:275])\n",
    "\n",
    "# in_processor = ZafarInProcessor(mitigating_attributes, discriminated)\n",
    "# in_processor.fit(features[:275], labels[:275], demographics[:275])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores per group for the SVC: {0: 0.6465028355387523, 1: 0.5846267553584626, 'all': 0.6118861607142857}\n",
      "scores per group for the in-processed with Chakraborty: {0: 0.717391304347826, 1: 0.6921655580192165, 'all': 0.7004743303571429}\n"
     ]
    }
   ],
   "source": [
    "in_pred, _ = in_processor.predict(features[275:], labels[275:], demographics[275:])\n",
    "in_proba = in_processor.predict_proba(features[275:], demographics[275:])\n",
    "\n",
    "fairness = BinaryFairnessScorer(mitigating_scores, discriminated, np.unique(labels))\n",
    "in_scores = fairness.get_fairness_scores(labels[275:], in_pred, in_proba, demographics[275:])\n",
    "print('scores per group for the SVC:', scores['sex']['roc'])\n",
    "print('scores per group for the in-processed with Chakraborty:', pre_scores['sex']['roc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores per group for the SVC: {0: 0.6465028355387523, 1: 0.5846267553584626, 'all': 0.6118861607142857}\n",
      "scores per group for the postprocessed from SVC to kamiran: {0: 0.553875236294896, 1: 0.5384331116038432, 'all': 0.5491071428571429}\n"
     ]
    }
   ],
   "source": [
    "# clf_svc = StandardScalingSVCClassifier(kernel='linear', C=0.001)\n",
    "clf_svc = GARFClassifier()\n",
    "_ = clf_svc.fit(new_x[:275], new_y[:275])\n",
    "pre_svc_pred = clf_svc.predict(features[275:])\n",
    "pre_svc_proba = clf_svc.predict_proba(features[275:])\n",
    "post_processor = KamiranPostProcessor(mitigating_attributes, discriminated)\n",
    "post_predictions, post_probas = post_processor.fit_transform(\n",
    "    clf_dt, features[275:], labels[275:], pre_svc_pred, pre_svc_proba, demographics[275:]\n",
    ")\n",
    "\n",
    "\n",
    "fairness = BinaryFairnessScorer(mitigating_scores, discriminated, np.unique(labels))\n",
    "pre_scores = fairness.get_fairness_scores(labels[275:], post_predictions, post_probas, demographics[275:])\n",
    "print('scores per group for the SVC:', scores['sex']['roc'])\n",
    "print('scores per group for the postprocessed from SVC to kamiran:', pre_scores['sex']['roc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T19:52:16.446367Z",
     "iopub.status.busy": "2025-07-19T19:52:16.446091Z",
     "iopub.status.idle": "2025-07-19T19:52:20.111081Z",
     "shell.execute_reply": "2025-07-19T19:52:20.110600Z",
     "shell.execute_reply.started": "2025-07-19T19:52:16.446349Z"
    }
   },
   "outputs": [],
   "source": [
    "# post_processor = KamiranPostProcessor(mitigating_attributes, discriminated)\n",
    "# post_predictions, post_probas = post_processor.fit_transform(\n",
    "#     clf_dt, features[275:], labels[275:], dt_pred, dt_probas, demographics[275:]\n",
    "# )\n",
    "\n",
    "# post_processor = PleissPostProcessor(mitigating_attributes, discriminated)\n",
    "# post_predictions, post_probas = post_processor.fit_transform(\n",
    "#     #clf_dt, features[275:], labels[275:], dt_pred, dt_probas, demographics[275:]\n",
    "# )\n",
    "\n",
    "# post_processor = SnelPostProcessor(mitigating_attributes, discriminated)\n",
    "# post_predictions, post_probas = post_processor.fit_transform(\n",
    "#     clf_dt, features[275:], labels[275:], dt_pred, dt_probas, demographics[275:]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a1fed0735b18420d080e2a506f952949ec34d8aa416c31604a927a6abbe4540"
  },
  "kernelspec": {
   "display_name": "Python 3.11.13 64-bit ('debiased': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
