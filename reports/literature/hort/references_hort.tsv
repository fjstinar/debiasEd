Ref number	reference	citations	survey	pipeline	type	comment
1	2001. Dutch Central Bureau for Statistics Volkstelling. Retrieved from http://easy.dans.knaw.nl/dms	8	hort			
2	2016. Medical Expenditure Panel Survey dataset. Retrieved from https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-192	35	hort			
3	2017. The Heritage Health Prize dataset. Retrieved from https://www.kaggle.com/c/hhp	6	hort			
4	"2017. Stop, Question and Frisk dataset. Retrieved from http://www1.nyc.gov/site/nypd/stats/reports-analysis/stopfrisk.page"	x	hort			
5	2018. Home Credit Default Risk. Retrieved from https://www.kaggle.com/c/home-credit-default-risk	7	hort			
6	2019. National longitudinal surveys of youth data set. Retrieved from: www.bls.gov/nls/	x	hort			
7	"Annie Abay, Yi Zhou, Nathalie Baracaldo, Shashank Rajamoni, Ebube Chuba, and Heiko Ludwig. 2020. Mitigating bias in federated learning. arXiv preprint arXiv:2012.02447 (2020)."	97	hort	in-processing	regularisation	reweighing
8	"Adel Abusitta, Esma Aïmeur, and Omar Abdel Wahab. 2019. Generative adversarial networks for mitigating biases in machine learning systems. arXiv preprint arXiv:1905.09972 (2019)."	29	hort	pre-processing	sampling	generative
9	"Tameem Adel, Isabel Valera, Zoubin Ghahramani, and Adrian Weller. 2019. One-network adversarial fairness. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 2412–2420."	144	hort	in-processing	adversarial	nn
10	"Philip Adler, Casey Falk, Sorelle A. Friedler, Tionney Nix, Gabriel Rybeck, Carlos Scheidegger, Brandon Smith, and Suresh Venkatasubramanian. 2018. Auditing black-box models for indirect influence. Knowl. Inf. Syst. 54, 1 (2018), 95–122."	373	hort	post-processing	input	
11	"Alekh Agarwal, Alina Beygelzimer, Miroslav Dudík, John Langford, and Hanna Wallach. 2018. A reductions approach to fair classification. In Proceedings of the International Conference on Machine Learning. PMLR, 60–69."	1265	hort	in-processing	adversarial	
12	"Alekh Agarwal, Miroslav Dudík, and Zhiwei Steven Wu. 2019. Fair regression: Quantitative definitions and reduction-based algorithms. In Proceedings of the International Conference on Machine Learning. PMLR, 120–129."	309	hort	in-processing	constraints	
13	"Sushant Agarwal and Amit Deshpande. 2022. On the power of randomization in fair classification and representation. In Proceedings of the ACM Conference on Fairness, Accountability, and Transparency (FAccT’22). Association for Computing Machinery, New York, NY, 15421551. DOI:"	9	hort	in-processing	adjusted	
14	"Sina Aghaei, Mohammad Javad Azizi, and Phebe Vayanos. 2019. Learning optimal and fair decision trees for non-discriminative decision-making. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 1418–1426."	219	hort	in-processing	regularisation	
15	Ibrahim Alabdulmohsin. 2020. Fair classification via unconstrained optimization. arXiv preprint arXiv:2005.14621 (2020).	5	hort	post-processing	output	group_dependent
16	"Ibrahim Alabdulmohsin, Jessica Schrouff, and Oluwasanmi Koyejo. 2022. A reduction to binary approach for debiasing multiclass datasets. arXiv preprint arXiv:2205.15860 (2022)."	13	hort	pre-processing	relabelling	
17	"Ibrahim M. Alabdulmohsin and Mario Lucic. 2021. A near-optimal algorithm for debiasing trained machine learning models. Adv. Neural Inf. Process. Syst. 34 (2021), 8072–8084."	28	hort	post-processing	output	
18	"Daniel Alabi, Nicole Immorlica, and Adam Kalai. 2018. Unleashing linear optimizers for group-fair learning and optimization. In Proceedings of the Conference on Learning Theory. PMLR, 2043–2066."	34	hort	in-processing	adjusted	
19	"Wael Alghamdi, Hsiang Hsu, Haewon Jeong, Hao Wang, P. Winston Michalak, Shahab Asoodeh, and Flavio P. Calmon. 2022. Beyond adult and COMPAS: Fairness in multi-class prediction. arXiv preprint arXiv:2206.07801 (2022)."	15	hort	post-processing	output	
20	"Abdulaziz A. Almuzaini, Chidansh A. Bhatt, David M. Pennock, and Vivek K. Singh. 2022. ABCinML: Anticipatory bias correction in machine learning applications. In Proceedings of the ACM Conference on Fairness, Accountability, and Transparency (FAccT’22). Association for Computing Machinery, New York, NY, 15521560. DOI:"	13	hort	pre-processing	sampling	reweighing
21	"Jack J. Amend and Scott Spurlock. 2021. Improving machine learning fairness with sampling and adversarial learning. J. Comput. Sci. Colleg. 36, 5 (2021), 14–23."	10	hort	in-processing	adversarial	upsampling
22	"Hadis Anahideh, Abolfazl Asudeh, and Saravanan Thirumuruganathan. 2022. Fair active learning. Expert Syst. Applic. 199 (2022), 116981. DOI"	77	hort	in-processing	adjusted	active_learning
23	"Christopher Anders, Plamen Pasliev, Ann-Kathrin Dombrowski, Klaus-Robert Müller, and Pan Kessel. 2020. Fairwashing explanations with off-manifold detergent. In Proceedings of the International Conference on Machine Learning. PMLR, 314–323"	102	hort			
24	"Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. Machine bias. ProPublica. Retrieved from https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing"	3991	hort			
25	Online Appendix. 2022. Online Appendix: Survey Results. Retrieved from https://solar.cs.ucl.ac.uk/os/softwarefairness.html	X	hort			
26	"Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. 2002. Finite-time analysis of the multiarmed bandit problem. Mach. Learn. 47, 2 (2002), 235–256"	8492	hort	in-processing	adjusted	bandits
27	"Pranjal Awasthi, Matthäus Kleindessner, and Jamie Morgenstern. 2020. Equalized odds postprocessing under imperfect group information. In Proceedings of the International Conference on Artificial Intelligence and Statistics. PMLR, 1770–1780."	100	hort	post-processing	classifier	equal_odds
28	"Sina Baharlouei, Maher Nouiehed, Ahmad Beirami, and Meisam Razaviyayn. 2020. Rényi fair inference. In Proceedings of the 8th International Conference on Learning Representations."	97	hort	in-processing	regularisation	
29	"Ananth Balashankar, Alyssa Lees, Chris Welty, and Lakshminarayanan Subramanian. 2019. What is fair? Exploring Pareto-efficiency for fairness constrained classifiers. arXiv preprint arXiv:1910.14120 (2019)."	26	hort	in-processing	constraints	
30	"Mislav Balunović, Anian Ruoss, and Martin Vechev. 2022. Fair normalizing flows. In Proceedings of the International Conference on Learning Representations. Retrieved from https://openreview.net/forum?id=BrFIKuxrZE"	39	hort	pre-processing	representation	normalising
31	"Niels Bantilan. 2018. Themis-ML: A fairness-aware machine learning interface for end-to-end discrimination discovery and mitigation. J. Technol. Hum. Servic. 36, 1 (2018), 15–30."	99	hort			
32	"Michelle Bao, Angela Zhou, Samantha Zottola, Brian Brubach, Sarah Desmarais, Aaron Horowitz, Kristian Lum, and Suresh Venkatasubramanian. 2021. It’s compaslicated: The messy relationship between RAI datasets and algorithmic fairness benchmarks. arXiv preprint arXiv:2106.05498 (2021)."	115	hort			
33	"Luciano Baresi, Chiara Criscuolo, and Carlo Ghezzi. 2023. Understanding fairness requirements for ML-based software. In 2023 IEEE 31st International Requirements Engineering Conference (RE). IEEE, 341–346."	7	hort			
34	"Solon Barocas and Andrew D. Selbst. 2016. Big data’s disparate impact. Calif. L. Rev. 104 (2016), 671."	4918	hort			
35	Yahav Bechavod and Katrina Ligett. 2017. Penalizing unfairness in binary classification. arXiv preprint arXiv:1707.00044 (2017).	137	hort	in-processing	regularisation	
36	"Rachel K. E. Bellamy, Kuntal Dey, Michael Hind, Samuel C. Hoffman, Stephanie Houde, Kalapriya Kannan, Pranay Lohia, Jacquelyn Martino, Sameep Mehta, Aleksandra Mojsilovic, Seema Nagar, Karthikeyan Natesan Ramamurthy, John Richards, Diptikalyan Saha, Prasanna Sattigeri, Moninder Singh, Kush R. Varshney, and Yunfeng Zhang. 2018. AI Fairness 360: An extensible toolkit for detecting, understanding, and mitigating unwanted algorithmic bias. arXivpreprint arXiv:1810.01943 (2018)."	1612	hort			
37	"Richard Berk, Hoda Heidari, Shahin Jabbari, Matthew Joseph, Michael Kearns, Jamie Morgenstern, Seth Neel, and Aaron Roth. 2017. A convex framework for fair regression. arXiv preprint arXiv:1706.02409 (2017)"	393	hort	in-processing	regularisation	
38	"Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, and Aaron Roth. 2018. Fairness in criminal justice risk assessments: The state of the art. Sociological Methods & Research 1 (2018), 42."	1192	hort			
39	"Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Allison Woodruff, Christine Luu, Pierre Kreitmann, Jonathan Bischof, and Ed H. Chi. 2019. Putting fairness principles into practice: Challenges, metrics, and improvements. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. 453–459"	163	hort	in-processing	adversarial	nn
40	"Alex Beutel, Jilin Chen, Zhe Zhao, and Ed H. Chi. 2017. Data decisions and theoretical implications when adversarially learning fair representations. arXiv preprint arXiv:1707.00075 (2017)."	513	hort	in-processing	adversarial	nn
41	"Peter J. Bickel, Eugene A. Hammel, and J. William O’Connell. 1975. Sex bias in graduate admissions: Data from Berkeley. Science 187, 4175 (1975), 398–404."	882	hort			
42	"Sarah Bird, Miro Dudík, Richard Edgar, Brandon Horn, Roman Lutz, Vanessa Milan, Mehrnoosh Sameki, Hanna Wallach, and Kathleen Walker. 2020. FairLearn: A Toolkit for Assessing and Improving Fairness in AI. Technical Report MSR-TR-2020-32. Microsoft."	439	hort			
43	"William Blanzeisky and Pádraig Cunningham. 2022. Using Pareto simulated annealing to address algorithmic bias in machine learning. Knowl. Eng. Rev. 37 (2022), e5. DOI:"	8	hort	in-processing	compositionnal	pareto
44	"Su Lin Blodgett, Solon Barocas, Hal Daumé III, and Hanna Wallach. 2020. Language (technology) is power: A critical survey of “bias” in NLP. arXiv preprint arXiv:2005.14050 (2020)."	1238	hort			
45	"Ruth G. Blumrosen. 1978. Wage discrimination, job segregation, and the Title VII of the Civil Rights Act of 1964. U. Mich. JL Reform. 12 (1978), 397."	375	hort			
46	Stelios Boulitsakis-Logothetis. 2022. Fairness-aware naive Bayes classifier for data with multiple sensitive features. arXiv preprint arXiv:2202.11499 (2022).	7	hort	in-processing	compositionnal	different_clf
47	"Toon Calders, Faisal Kamiran, and Mykola Pechenizkiy. 2009. Building classifiers with independency constraints. In Proceedings of the IEEE International Conference on Data Mining Workshops. IEEE, 13–18."	694	hort	pre-processing	sampling	reweighing
48	"Toon Calders, Asim Karim, Faisal Kamiran, Wasif Ali, and Xiangliang Zhang. 2013. Controlling attribute effect in linear regression. In Proceedings of the IEEE 13th International Conference on Data Mining. IEEE, 71–80"	186	hort	in-processing	constraints	
49	"Toon Calders and Sicco Verwer. 2010. Three naive Bayes approaches for discrimination-free classification. Data Min. Knowl. Discov. 21, 2 (2010), 277–292."	1062	hort	post-processing	classifier	naive_bayes
50	"Flavio Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan Ramamurthy, and Kush R. Varshney. 2017. Optimized pre-processing for discrimination prevention. In Proceedings of the International Conference on Advances in Neural Information Processing Systems. 3992–4001."	1011	hort	pre-processing	representation	optimisation
51	"Antonio Candelieri, Andrea Ponti, and Francesco Archetti. 2022. Fair and green hyperparameter optimization via multi-objective and multiple information source Bayesian optimization. arXiv preprint arXiv:2205.08835 (2022)"	15	hort	in-processing	adjusted	
52	Simon Caton and Christian Haas. 2020. Fairness in machine learning: A survey. arXiv preprint arXiv:2010.04053 (2020)	687	hort			
53	"L. Elisa Celis, Lingxiao Huang, Vijay Keswani, and Nisheeth K. Vishnoi. 2019. Classification with fairness constraints: A meta-algorithm with provable guarantees. In Proceedings of the Conference on Fairness, Accountability, and Transparency. 319–328."	362	hort	in-processing	constraints	meta
54	"L. Elisa Celis, Lingxiao Huang, Vijay Keswani, and Nisheeth K. Vishnoi. 2021. Fair classification with noisy protected attributes: A framework with provable guarantees. In Proceedings of the International Conference on Machine Learning. PMLR, 1349–1361."	62	hort	in-processing	constraints	
55	L. Elisa Celis and Vijay Keswani. 2019. Improved adversarial learning for fair classification. arXiv preprint arXiv:1901.10443 (2019).	58	hort	in-processing	adversarial	
56	"L. Elisa Celis, Vijay Keswani, and Nisheeth Vishnoi. 2020. Data preprocessing to mitigate bias: A maximum entropy based approach. In Proceedings of the International Conference on Machine Learning. PMLR, 1349–1359"	68	hort	pre-processing	sampling	reweighing
57	"L. Elisa Celis, Anay Mehrotra, and Nisheeth Vishnoi. 2021. Fair classification with adversarial perturbations. Adv. Neural Inf. Process. Syst. 34 (2021), 8158–8171."	46	hort	in-processing	constraints	
58	"Mattia Cerrato, Alesia Vallenas Coronel, Marius Köppel, Alexander Segner, Roberto Esposito, and Stefan Kramer. 2022. Fair interpretable representation learning with correction vectors. arXiv preprint arXiv:2202.03078 (2022)."	7	hort	pre-processing	representation	normalising
59	"Junyi Chai and Xiaoqian Wang. 2022. Fairness with adaptive weights. In Proceedings of the International Conference on Machine Learning. PMLR, 2853–2866"	42	hort	pre-processing	sampling	reweighing
60	"Joymallya Chakraborty, Suvodeep Majumder, and Tim Menzies. 2021. Bias in machine learning software: Why? How? What to do? In Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE’21). Association for Computing Machinery, New York, NY, 429440. DOI"	215	hort	pre-processing	sampling	smote_like
61	"Joymallya Chakraborty, Suvodeep Majumder, and Huy Tu. 2022. Fair-SSL: Building fair ML software with less data. In Proceedings of the International Workshop on Equitable Data and Technology (FairWare’22)."	11	hort	pre-processing	latent	latent_groupmembership
62	"Joymallya Chakraborty, Suvodeep Majumder, Zhe Yu, and Tim Menzies. 2020. Fairway: A Way to Build Fair ML Software. Association for Computing Machinery, New York, NY, 654665. DOI:"	137	hort	in-processing	adjusted	hyperparameters_tuning
63	"Joymallya Chakraborty, Tianpei Xia, Fahmid M. Fahid, and Tim Menzies. 2019. Software engineering for fairness: A case study with hyperparameter optimization. arXiv preprint arXiv:1905.05786 (2019)."	47	hort	in-processing	adjusted	hyperparameters_tuning
64	"Nitesh V. Chawla, Kevin W. Bowyer, Lawrence O. Hall, and W. Philip Kegelmeyer. 2002. SMOTE: Synthetic minority over-sampling technique. J. Artif. Intell. Res. 16 (2002), 321–357"	32276	hort	pre-processing	sampling	smote_like
65	"Canyu Chen, Yueqing Liang, Xiongxiao Xu, Shangyu Xie, Yuan Hong, and Kai Shu. 2022. On fair classification with mostly private sensitive attributes. arXiv preprint arXiv:2207.08336 (2022)."	8	hort	in-processing	adversarial	latent_groupmembership
66	"Irene Chen, Fredrik D. Johansson, and David Sontag. 2018. Why is my classifier discriminatory? Adv. Neural Inf. Process. Syst. 31 (2018)."	527	hort	pre-processing	sampling	
67	"Jiahao Chen, Nathan Kallus, Xiaojie Mao, Geoffry Svacha, and Madeleine Udell. 2019. Fairness under unawareness: Assessing disparity when protected class is unobserved. In Proceedings of the Conference on Fairness, Accountability, and Transparency. 339–348."	356	hort			
68	"Zhenpeng Chen, Jie M. Zhang, Max Hort, Federica Sarro, and Mark Harman. 2022. Fairness testing: A comprehensive survey and analysis of trends. arXiv e-prints (2022), arXiv–2207."	55	hort			
69	"Zhenpeng Chen, Jie M. Zhang, Federica Sarro, and Mark Harman. 2022. MAAT: A novel ensemble approach to addressing fairness and performance bugs for machine learning software. In Proceedings of the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE’22)."	61	hort	in-processing	compositionnal	ensemble
70	"Zhenpeng Chen, Jie M. Zhang, Federica Sarro, and Mark Harman. 2023. A comprehensive empirical study of bias mitigation methods for machine learning classifiers. ACM Trans. Softw. Eng. Methodol. 32, 4 (2023), 106:1–106:30."	71	hort			
71	"Zhenpeng Chen, Jie M. Zhang, Federica Sarro, and Mark Harman. 2024. Fairness improvement with multiple protected attributes: How far are we? In Proceedings of the 46th ACM/IEEE International Conference on Software Engineering (ICSE’24)."	15	hort			
72	"Silvia Chiappa. 2019. Path-specific counterfactual fairness. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 7801–7808."	384	hort	post-processing	output	counterfactual
73	"Silvia Chiappa and William S. Isaac. 2018. A causal Bayesian networks viewpoint on fairness. In Proceedings of the IFIP International Summer School on Privacy and Identity Management. Springer, 3–20."	98	hort	in-processing	adjusted	
74	"Jaewoong Cho, Gyeongjo Hwang, and Changho Suh. 2020. A fair classifier using kernel density estimation. Adv. Neural Inf. Process. Syst. 33 (2020), 15088–15099."	76	hort	in-processing	constraints	
75	"YooJung Choi, Meihua Dang, and Guy Van den Broeck. 2021. Group fairness by probabilistic modeling with latent fair decisions. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 12051–12059."	40	hort	in-processing	constraints	
76	Alexandra Chouldechova and Aaron Roth. 2018. The frontiers of fairness in machine learning. arXiv preprint arXiv:1810.08810 (2018)	412	hort			
77	Ching-Yao Chuang and Youssef Mroueh. 2021. Fair mixup: Fairness via interpolation. In Proceedings of the International Conference on Learning Representations. Retrieved from https://openreview.net/forum?id=DNl5s5BXeBn	149	hort	in-processing	regularisation	
78	"Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto, and Massimiliano Pontil. 2019. Leveraging labeled and unlabeled data for consistent fair binary classification. Adv. Neural Inf. Process. Syst. 32 (2019)."	111	hort	post-processing	output	group_dependent
79	"Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto, and Massimiliano Pontil. 2020. Fair regression via plug-in estimator and recalibration with statistical guarantees. Adv. Neural Inf. Process. Syst. 33 (2020), 19137–19148."	53	hort	post-processing	classifier	
80	"Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto, and Massimiliano Pontil. 2020. Fair regression with Wasserstein barycenters. Adv. Neural Inf. Process. Syst. 33 (2020), 7321–7331."	122	hort	post-processing	classifier	regression
81	Evgenii Chzhen and Nicolas Schreuder. 2020. A minimax framework for quantifying risk-fairness trade-off in regression. arXiv preprint arXiv:2007.14265 (2020).	37	hort	post-processing	classifier	
82	"Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq. 2017. Algorithmic decision making and the cost of fairness. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 797–806."	1558	hort	in-processing	constraints	
83	"Paulo Cortez, António Cerdeira, Fernando Almeida, Telmo Matos, and José Reis. 2009. Modeling wine preferences by data mining from physicochemical properties. Decis. Supp. Syst. 47, 4 (2009), 547–553."	1751	hort			
84	"Paulo Cortez and Alice Maria Gonçalves Silva. 2008. Using data mining to predict secondary school studentperformance. In Proceedings of 5th Annual Future Business Technology Conference. Porto, 5–12."	986	hort			
85	"Andrew Cotter, Maya Gupta, Heinrich Jiang, Nathan Srebro, Karthik Sridharan, Serena Wang, Blake Woodworth, and Seungil You. 2019. Training well-generalizing classifiers for fairness metrics and other data-dependent constraints. In Proceedings of the International Conference on Machine Learning. PMLR, 1397–1405."	120	hort	in-processing	constraints	
86	"Andrew Cotter, Heinrich Jiang, Maya R. Gupta, Serena Wang, Taman Narayan, Seungil You, and Karthik Sridharan. 2019. Optimization with non-differentiable constraints with applications to fairness, recall, churn, and other goals. J. Mach. Learn. Res. 20, 172 (2019), 1–59."	175	hort	in-processing	constraints	
87	"Andrew Cotter, Heinrich Jiang, and Karthik Sridharan. 2019. Two-player games for efficient non-convex constrained optimization. In Algorithmic Learning Theory. PMLR, 300–332."	140	hort	in-processing	constraints	
88	"Elliot Creager, David Madras, Jörn-Henrik Jacobsen, Marissa Weis, Kevin Swersky, Toniann Pitassi, and Richard Zemel. 2019. Flexibly fair representation learning by disentanglement. In Proceedings of the International Conference on Machine Learning. PMLR, 1436–1445."	400	hort	pre-processing	representation	vaes
89	"André F. Cruz, Pedro Saleiro, Catarina Belém, Carlos Soares, and Pedro Bizarro. 2021. Promoting fairness through hyperparameter optimization. In Proceedings of the IEEE International Conference on Data Mining (ICDM’21). 1036–1041. DOI:"	28	hort	in-processing	adjusted	hyperparameters_tuning
90	"André Miguel Ferreira da Cruz. 2020. Fairness-aware hyperparameter optimization: An application to fraud detection. Retrieved on June 12, 2022 https://repositorio-aberto.up.pt/bitstream/10216/128959/2/414778.pdf."	4	hort	in-processing	adjusted	hyperparameters_tuning
91	"Damien Dablain, Bartosz Krawczyk, and Nitesh Chawla. 2022. Towards A holistic view of bias in machine learning: Bridging algorithmic fairness and imbalanced learning. arXiv preprint arXiv:2207.06084 (2022)."	15	hort	pre-processing	sampling	smote_like
92	"Nilesh Dalvi, Pedro Domingos, Sumit Sanghai, and Deepak Verma. 2004. Adversarial classification. In Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 99–108."	1340	hort			
93	Jeffrey Dastin. 2018. Amazon Scraps Secret AI Recruiting Tool that Showed Bias against Women. Retrieved from https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G	2223	hort			
94	"Pieter Delobelle, Paul Temple, Gilles Perrouin, Benoît Frénay, Patrick Heymans, and Bettina Berendt. 2020. Ethical adversaries: Towards mitigating unfairness with adversarial machine learning. In Proceedings of the Conference on Bias and Fairness in AI (BIAS’20)."	51	hort	in-processing	adversarial	nn
95	"Zhun Deng, Jiayao Zhang, Linjun Zhang, Ting Ye, Yates Coley, Weijie J. Su, and James Zou. 2022. FIFA: Making fairness more generalizable in classifiers trained on imbalanced data. arXiv preprint arXiv:2206.02792 (2022)."	17	hort	in-processing	regularisation	
96	"Pietro G. Di Stefano, James M. Hickey, and Vlasios Vasileiou. 2020. Counterfactual fairness: Removing direct effects through regularization. arXiv preprint arXiv:2002.10774 (2020)."	23	hort	in-processing	regularisation	
97	"Emily Diana, Wesley Gill, Michael Kearns, Krishnaram Kenthapadi, Aaron Roth, and Saeed Sharifi-Malvajerdi. 2022. Multiaccurate proxies for downstream fairness. In Proceedings of the ACM Conference on Fairness, Accountability, and Transparency (FAccT’22). Association for Computing Machinery, New York, NY, 12071239. DOI:"	31	hort	pre-processing	latent	latent_groupmembership
98	"Christos Dimitrakakis, Yang Liu, David C. Parkes, and Goran Radanovic. 2019. Bayesian fairness. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 509–516"	47	hort	in-processing	adjusted	bayesian
99	"Frances Ding, Moritz Hardt, John Miller, and Ludwig Schmidt. 2021. Retiring adult: New datasets for fair machine learning. Adv. Neural Inf. Process. Syst. 34 (2021), 6478–6490."	429	hort			
100	"Jiahao Ding, Xinyue Zhang, Xiaohuan Li, Junyi Wang, Rong Yu, and Miao Pan. 2020. Differentially private and fair classification via calibrated functional mechanism. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 622–629."	54	hort	in-processing	constraints	
101	Yasmine Djebrouni. 2022. Towards bias mitigation in federated learning. In Proceedings of the 16th EuroSys Doctoral Workshop	5	hort	in-processing	adjusted	
102	"Hyungrok Do, Preston Putzel, Axel S. Martin, Padhraic Smyth, and Judy Zhong. 2022. Fair generalized linear models with a convex penalty. In Proceedings of the International Conference on Machine Learning. PMLR, 5286–5308"	16	hort	in-processing	regularisation	
103	"Michele Donini, Luca Oneto, Shai Ben-David, John Shawe-Taylor, and Massimiliano Pontil. 2018. Empirical risk minimization under fairness constraints. In Proceedings of the 32nd International Conference on Neural Information Processing Systems. 2796–2806."	525	hort	in-processing	constraints	
104	"Mengnan Du, Subhabrata Mukherjee, Guanchu Wang, Ruixiang Tang, Ahmed Awadallah, and Xia Hu. 2021. Fairness via representation neutralization. Adv. Neural Inf. Process. Syst. 34 (2021), 12091–12103."	85	hort	post-processing	classifier	nn
105	"Wei Du and Xintao Wu. 2021. Fair and robust classification under sample selection bias. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management (CIKM’21). Association for Computing Machinery, New York, NY, 29993003. DOI:"	35	hort	in-processing	constraints	reweighing
106	"Flavio du Pin Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan Ramamurthy, and Kush R. Varshney. 2018. Data pre-processing for discrimination prevention: Information-theoretic optimization and analysis. IEEE J. Select. Topics Sig. Process. 12, 5 (2018), 1106–1119"	41	hort	pre-processing	representation	optimisation
107	Dheeru Dua and Casey Graff. 2017. UCI Machine Learning Repository. Retrieved from http://archive.ics.uci.edu/ml	7777	hort			
108	"Jannik Dunkelau and Michael Leuschel. 2019. Fairness-aware machine learning. Retrieved on June 12, 2022 https://stups.hhu-hosting.de/downloads/pdf/fairness-survey.pdf"	16	hort			
109	"Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. 2012. Fairness through awareness. In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference. 214–226"	4479	hort	in-processing	constraints	individual_fairness
110	"Cynthia Dwork, Nicole Immorlica, Adam Tauman Kalai, and Max Leiserson. 2018. Decoupled classifiers for group-fair and efficient machine learning. In Proceedings of the Conference on Fairness, Accountability and Transparency. PMLR, 119–133."	336	hort	in-processing	compositionnal	transfer
111	Harrison Edwards and Amos Storkey. 2015. Censoring representations with an adversary. arXiv preprint arXiv:1511.05897 (2015).	621	hort	pre-processing	representation	adversarial
112	"Michael Emmerich and André H. Deutz. 2018. A tutorial on multiobjective optimization: fundamentals and evolutionary methods. Nat. Comput. 17, 3 (2018), 585–609."	780	hort	in-processing	adjusted	ap_star
113	"Simon Aagaard Enni and Ira Assent. 2018. Using balancing terms to avoid discrimination in classification. In Proceedings of the IEEE International Conference on Data Mining (ICDM’18). IEEE, 947–952."	5	hort	in-processing	regularisation	
114	"Yahya H. Ezzeldin, Shen Yan, Chaoyang He, Emilio Ferrara, and Salman Avestimehr. 2021. FairFed: Enabling group fairness in federated learning. arXiv preprint arXiv:2110.00857 (2021)."	176	hort	in-processing	adjusted	
115	"Alessandro Fabris, Stefano Messina, Gianmaria Silvello, and Gian Antonio Susto. 2022. Algorithmic fairness datasets: The story so far. Data Min. Knowl. Discov. 36, 6 (2022), 2074–2152."	115	hort			
116	"Golnoosh Farnadi, Behrouz Babaki, and Lise Getoor. 2018. Fairness in relational domains. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. 108–114."	44	hort	in-processing	constraints	
117	"Elaine Fehrman, Awaz K. Muhammad, Evgeny M. Mirkes, Vincent Egan, and Alexander N. Gorban. 2017. The five factor model of personality and evaluation of drug consumption risk. In Data Science. Springer, 231–242."	140	hort			
118	"Michael Feldman, Sorelle A. Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubramanian. 2015. Certifying and removing disparate impact. In Proceedings of the 21st ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 259–268."	2323	hort	pre-processing	relabelling	perturbation
119	"Rui Feng, Yang Yang, Yuehan Lyu, Chenhao Tan, Yizhou Sun, and Chunping Wang. 2019. Learning fair representations via an adversarial framework. arXiv preprint arXiv:1904.13341 (2019)."	65	hort	pre-processing	representation	adversarial
120	"Benjamin Fish, Jeremy Kun, and Adám D. Lelkes. 2015. Fair boosting: A case study. In Proceedings of the Workshop on Fairness, Accountability, and Transparency in Machine Learning. Citeseer."	35	hort	post-processing	output	confidence
121	"Benjamin Fish, Jeremy Kun, and Ádám D. Lelkes. 2016. A confidence-based approach for balancing fairness and accuracy. In Proceedings of the SIAM International Conference on Data Mining. SIAM, 144–152"	279	hort	post-processing	output	confidence
122	"Hortense Fong, Vineet Kumar, Anay Mehrotra, and Nisheeth K. Vishnoi. 2021. Fairness for AUC via Feature Augmentation. arXiv preprint arXiv:2111.12823 (2021)."	14	hort	pre-processing	representation	addition_features
123	"Sorelle A. Friedler, Carlos Scheidegger, Suresh Venkatasubramanian, Sonam Choudhary, Evan P. Hamilton, and Derek Roth. 2019. A comparative study of fairness-enhancing interventions in machine learning. In Proceedings of the Conference on Fairness, Accountability, and Transparency. ACM, 329–338."	812	hort			
124	"Kazuto Fukuchi, Toshihiro Kamishima, and Jun Sakuma. 2015. Prediction with model-based neutrality. IEICE Trans. Inf. Syst. 98, 8 (2015), 1503–1516."	58	hort	in-processing	constraints	
125	Kazuto Fukuchi and Jun Sakuma. 2015. Fairness-aware learning with restriction of universal dependency using f-divergences. arXiv preprint arXiv:1506.07721 (2015).	5	hort	in-processing	constraints	
126	"Sainyam Galhotra, Karthikeyan Shanmugam, Prasanna Sattigeri, and Kush R. Varshney. 2022. Causal Feature Selection for Algorithmic Fairness. In Proceedings of the International Conference on Management of Data (SIGMOD’22). Association for Computing Machinery, New York, NY, 276285. DOI:"	40	hort	pre-processing	representation	addition_features
127	"Xuanqi Gao, Juan Zhai, Shiqing Ma, Chao Shen, Yufei Chen, and Qian Wang. 2022. FairNeuron: Improving deep neural network fairness with adversary games on selective neurons. In Proceedings of the 44th International Conference on Software Engineering (ICSE’22). Association for Computing Machinery, New York, NY, 921933. DOI"	39	hort	in-processing	adjusted	
128	"Adriana Solange Garcia de Alford, Steven K. Hayden, Nicole Wittlin, and Amy Atwood. 2020. Reducing age bias in machine learning: An algorithmic approach. SMU Data Sci. Rev. 3, 2 (2020), 11"	9	hort	in-processing	adversarial	
129	"Bhavya Ghai, Mihir Mishra, and Klaus Mueller. 2022. Cascaded debiasing: Studying the cumulative effect of multiple fairness-enhancing interventions. arXiv preprint arXiv:2202.03734 (2022)"	12	hort			
130	"Stephen Gillen, Christopher Jung, Michael Kearns, and Aaron Roth. 2018. Online learning with an unknown fairness metric. Adv. Neural Inf. Process. Syst. 31 (2018)"	172	hort	in-processing	adversarial	individual_fairness
131	"Naman Goel, Mohammad Yaghini, and Boi Faltings. 2018. Non-discriminatory machine learning through convex fairness criteria. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence."	118	hort	in-processing	constraints	
132	"Gabriel Goh, Andrew Cotter, Maya Gupta, and Michael P. Friedlander. 2016. Satisfying real-world goals with dataset constraints. In Proceedings of the International Conference on Advances in Neural Information Processing Systems. 2415–2423."	254	hort	in-processing	constraints	
133	"Paula Gordaliza, Eustasio Del Barrio, Gamboa Fabrice, and Jean-Michel Loubes. 2019. Obtaining fairness using optimal transport theory. In Proceedings of the International Conference on Machine Learning. PMLR, 2357–2365."	193	hort	pre-processing	representation	optimisation
134	"Przemyslaw A. Grabowicz, Nicholas Perello, and Aarshee Mishra. 2022. Marrying fairness and explainability in supervised learning. In Proceedings of the ACM Conference on Fairness, Accountability, and Transparency. 1905–1916"	43	hort	post-processing	classifier	
135	"Vincent Grari, Oualid El Hajouji, Sylvain Lamprier, and Marcin Detyniecki. 2021. Learning unbiased representations via Rényi minimization. In Proceedings of the Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 749–764."	19	hort	pre-processing	representation	adversarial
136	"Vincent Grari, Sylvain Lamprier, and Marcin Detyniecki. 2021. Fairness-aware neural Rényi minimization for continuous features. In Proceedings of the 29th International Conference on International Joint Conferences on Artificial Intelligence. 2262–2268"	55	hort	in-processing	adversarial	
137	"Vincent Grari, Sylvain Lamprier, and Marcin Detyniecki. 2021. Fairness without the sensitive attribute via Causal Variational Autoencoder. arXiv preprint arXiv:2109.04999 (2021)."	32	hort	in-processing	adversarial	latent_groupmembership
138	"Vincent Grari, Boris Ruf, Sylvain Lamprier, and Marcin Detyniecki. 2019. Fair adversarial gradient tree boosting. In Proceedings of the IEEE International Conference on Data Mining (ICDM’19). IEEE, 1060–1065."	37	hort	in-processing	adversarial	
139	"Nina Grgić-Hlača, Muhammad Bilal Zafar, Krishna P. Gummadi, and Adrian Weller. 2018. Beyond distributive fairness in algorithmic decision making: Feature selection for procedurally fair learning. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 32."	249	hort	in-processing	constraints	selection_features
140	"Maya Gupta, Andrew Cotter, Mahdi Milani Fard, and Serena Wang. 2018. Proxy fairness. arXiv preprint arXiv:1806.11212 (2018)."	4	hort	post-processing	classifier	equal_odds
141	"Umang Gupta, Aaron Ferber, Bistra Dilkina, and Greg Ver Steeg. 2021. Controllable guarantees for fair outcomes via contrastive information estimation. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 7610–7619."	52	hort	pre-processing	representation	contrastive
142	Philipp Hacker and Emil Wiedemann. 2017. A continuous framework for fairness. arXiv preprint arXiv:1712.07924 (2017).	28	hort	pre-processing	representation	optimisation
143	"Sara Hajian and Josep Domingo-Ferrer. 2012. A methodology for direct and indirect discrimination prevention in data mining. IEEE Trans. Knowl. Data Eng. 25, 7 (2012), 1445–1459."	430	hort	pre-processing	relabelling	perturbation
144	"Moritz Hardt, Eric Price, and Nati Srebro. 2016. Equality of opportunity in supervised learning. In Proceedings of the International Conference on Advances in Neural Information Processing Systems. 3315–3323."	5027	hort	post-processing	classifier	equal_odds
145	"Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, and Percy Liang. 2018. Fairness without demographics in repeated loss minimization. In Proceedings of the International Conference on Machine Learning. PMLR, 1929–1938."	677	hort	in-processing	adjusted	distributionally_robust_optimisation
146	"Ursula Hébert-Johnson, Michael Kim, Omer Reingold, and Guy Rothblum. 2018. Multicalibration: Calibration for the (computationally-identifiable) masses. In Proceedings of the International Conference on Machine Learning. PMLR, 1939–1948."	483	hort	in-processing	adjusted	multicalibration
147	"Hoda Heidari, Claudio Ferrari, Krishna Gummadi, and Andreas Krause. 2018. Fairness behind a veil of ignorance: A welfare analysis for automated decision making. Adv. Neural Inf. Process. Syst. 31 (2018)."	143	hort	in-processing	constraints	
148	"James M. Hickey, Pietro G. Di Stefano, and Vlasios Vasileiou. 2020. Fairness by explicability and adversarial SHAP learning. In Proceedings of the Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 174–190."	31	hort	in-processing	regularisation	
149	"Kenneth Holstein, Jennifer Wortman Vaughan, Hal Daumé III, Miro Dudik, and Hanna Wallach. 2019. Improving fairness in machine learning systems: What do industry practitioners need? In Proceedings of the CHI Conference on Human Factors in Computing Systems. 1–16."	899	hort			
150	"Max Hort and Federica Sarro. 2021. Did you do your homework? Raising awareness on software fairness anddiscrimination. In 36th IEEE/ACM International Conference on Automated Software Engineering (ASE’21). IEEE, 1322–1326."	22	hort	in-processing	adjusted	hyperparameters_tuning
151	"Max Hort, Jie Zhang, Federica Sarro, and Mark Harman. 2021. Fairea: A model behaviour mutation approach to benchmarking bias mitigation methods. In Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering."	72	hort			
152	"Shengyuan Hu, Zhiwei Steven Wu, and Virginia Smith. 2022. Provably fair federated learning via bounded group loss. arXiv preprint arXiv:2203.10190 (2022)."	12	hort	in-processing	constraints	
153	"Tongxin Hu, Vasileios Iosifidis, Wentong Liao, Hang Zhang, Michael Ying Yang, Eirini Ntoutsi, and Bodo Rosenhahn. 2020. FairNN-conjoint learning of fair representations for fair decisions. In Proceedings of the International Conference on Discovery Science. Springer, 581–595."	25	hort	in-processing	adjusted	ap_star
154	"Lingxiao Huang and Nisheeth Vishnoi. 2019. Stable and fair classification. In Proceedings of the International Conference on Machine Learning. PMLR, 2879–2890."	88	hort	in-processing	regularisation	
155	"Xiaoling Huang, Zhenghui Li, Yilun Jin, and Wenyu Zhang. 2022. Fair-AdaBoost: Extending AdaBoost method to achieve fair classification. Expert Syst. Applic. 202 (2022), 117240."	50	hort	in-processing	adjusted	
156	"Ben Hutchinson and Margaret Mitchell. 2019. 50 years of test (un) fairness: Lessons for machine learning. In Proceedings of the Conference on Fairness, Accountability, and Transparency. 49–58."	415	hort			
157	"Alexey Ignatiev, Martin C. Cooper, Mohamed Siala, Emmanuel Hebrard, and Joao Marques-Silva. 2020. Towards formal fairness in machine learning. In Proceedings of the International Conference on Principles and Practice of Constraint Programming. Springer, 846–867."	48	hort	in-processing	adjusted	
158	"Eugenia Iofinova, Nikola Konstantinov, and Christoph H. Lampert. 2021. Flea: Provably fair multisource learning from unreliable training data. arXiv preprint arXiv:2106.11732 (2021)."	11	hort	pre-processing	sampling	downsampling
159	"Vasileios Iosifidis, Besnik Fetahu, and Eirini Ntoutsi. 2019. FAE: A fairness-aware ensemble framework. In Proceedings of the IEEE International Conference on Big Data (Big Data’19). IEEE, 1375–1380."	72	hort	post-processing	output	group_dependent
160	Vasileios Iosifidis and Eirini Ntoutsi. 2018. Dealing with bias via data augmentation in supervised learning scenarios. Jo Bates Paul D. Clough Robert Jäschke 24 (2018).	80	hort	pre-processing	sampling	smote_like
161	Vasileios Iosifidis and Eirini Ntoutsi. 2019. AdaFair: Cumulative fairness adaptive boosting. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 781–790	96	hort	in-processing	adjusted	boosting
162	"Vasileios Iosifidis and Eirini Ntoutsi. 2020. FABBOO-online fairness-aware learning under class imbalance. In Proceedings of the International Conference on Discovery Science. Springer, 159–174."	35	hort	in-processing	adjusted	boosting
163	"Vasileios Iosifidis, Arjun Roy, and Eirini Ntoutsi. 2022. Parity-based cumulative fairness-aware boosting. Knowl. Inf. Syst. (27 Jul.2022)"	5	hort	post-processing	classifier	
164	"Vasileios Iosifidis, Thi Ngoc Han Tran, and Eirini Ntoutsi. 2019. Fairness-enhancing interventions in stream classification. In Proceedings of the International Conference on Database and Expert Systems Applications. Springer, 261–276."	39	hort	pre-processing	sampling	reweighing
165	"Rashidul Islam, Shimei Pan, and James R. Foulds. 2021. Can we obtain fairness for free? In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. 586–596."	29	hort	in-processing	adjusted	hyperparameters_tuning
166	"Ayush Jaiswal, Daniel Moyer, Greg Ver Steeg, Wael AbdAlmageed, and Premkumar Natarajan. 2020. Invariant representations through adversarial forgetting. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 4272–4279."	47	hort	pre-processing	representation	adversarial
167	"Taeuk Jang, Pengyi Shi, and Xiaoqian Wang. 2022. Group-aware threshold adaptation for fair classification. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 36. 6988–6995."	36	hort	post-processing	output	group_dependent
168	"Taeuk Jang, Feng Zheng, and Xiaoqian Wang. 2021. Constructing a fair classifier with generated fair data. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 7908–7916."	42	hort	pre-processing	sampling	generative
169	"Heinrich Jiang and Ofir Nachum. 2020. Identifying and correcting label bias in machine learning. In Proceedings of the International Conference on Artificial Intelligence and Statistics. PMLR, 702–712."	361	hort	pre-processing	sampling	reweighing
170	"Ray Jiang, Aldo Pacchiano, Tom Stepleton, Heinrich Jiang, and Silvia Chiappa. 2020. Wasserstein fair classification. In Uncertainty in Artificial Intelligence. PMLR, 862–872."	207	hort	post-processing	classifier	logistic_regression
171	"Zhimeng Jiang, Xiaotian Han, Chao Fan, Fan Yang, Ali Mostafavi, and Xia Hu. 2022. Generalized demographic parity for group fairness. In Proceedings of the International Conference on Learning Representations. Retrieved from https://openreview.net/forum?id=YigKlMJwjye"	64	hort	in-processing	regularisation	
172	"Jiayin Jin, Zeru Zhang, Yang Zhou, and Lingfei Wu. 2022. Input-agnostic certified group fairness via Gaussian parameter smoothing. In Proceedings of the International Conference on Machine Learning. PMLR, 10340–10361."	17	hort	in-processing	compositionnal	different_clf
173	"James E. Johndrow and Kristian Lum. 2019. An algorithm for removing sensitive information: Application to race-independent recidivism prediction. Ann. Appl. Stat. 13, 1 (2019), 189–220."	203	hort	pre-processing	relabelling	perturbation
174	"Alistair E. W. Johnson, Tom J. Pollard, Lu Shen, Li-wei H. Lehman, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G. Mark. 2016. MIMIC-III, a freely accessible critical care database. Scient. Data 3, 1 (2016), 1–9."	7765	hort			
175	"Kory D. Johnson, Dean P. Foster, and Robert A. Stine. 2016. Impartial predictive modeling: Ensuring fairness in arbitrary models. Stat. Sci. (2016), 1."	45	hort	in-processing	adjusted	
176	"Matthew Joseph, Michael Kearns, Jamie Morgenstern, Seth Neel, and Aaron Roth. 2018. Meritocratic fairness for infinite and contextual bandits. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. 158–163."	60	hort	in-processing	adjusted	bandits
177	"Matthew Joseph, Michael Kearns, Jamie H. Morgenstern, and Aaron Roth. 2016. Fairness in learning: Classic and contextual bandits. Adv. Neural Inf. Process. Syst. 29 (2016)."	543	hort	in-processing	adjusted	bandits
178	"Christopher Jung, Michael Kearns, Seth Neel, Aaron Roth, Logan Stapleton, and Zhiwei Steven Wu. 2019. An algorithmic framework for fairness elicitation. arXiv preprint arXiv:1905.10660 (2019)."	36	hort	in-processing	constraints	individual_fairness
179	"Sangwon Jung, Sanghyuk Chun, and Taesup Moon. 2022. Learning fair classifiers with partially annotated group labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 10348–10357."	48	hort	pre-processing	latent	latent_groupmembership
180	"Peter Kairouz, Jiachun Liao, Chong Huang, Maunil Vyas, Monica Welfert, and Lalitha Sankar. 2022. Generating fair universal representations using adversarial models. IEEE Trans. Inf. Forens. Secur. 17 (2022), 1970–1985. DOI:"	24	hort	pre-processing	representation	adversarial
181	Mohammad Mahdi Kamani. 2020. Multiobjective optimization approaches for bias mitigation in machine learning. Ph. D. Dissertation. Pennsylvania State University.	2	hort	in-processing	adjusted	
182	"Mohammad Mahdi Kamani, Farzin Haddadpour, Rana Forsati, and Mehrdad Mahdavi. 2022. Efficient fair principalcomponent analysis. Machine Learning 111, 10 (2022), 3671–3702."	41	hort	pre-processing	representation	dim_reduction
183	"Faisal Kamiran and Toon Calders. 2009. Classifying without discriminating. In Proceedings of the 2nd International Conference on Computer, Control and Communication. IEEE, 1–6."	586	hort	pre-processing	relabelling	
184	"Faisal Kamiran and Toon Calders. 2010. Classification with no discrimination by preferential sampling. In Proceedings of the 19th Machine Learning Conference. Citeseer, 1–6."	201	hort	pre-processing	sampling	sample
185	"Faisal Kamiran and Toon Calders. 2012. Data preprocessing techniques for classification without discrimination. Knowl. Inf. Syst. 33, 1 (2012), 1–33."	1514	hort	pre-processing	sampling	sample
186	"aisal Kamiran, Toon Calders, and Mykola Pechenizkiy. 2010. Discrimination aware decision tree learning. In Proceedings of the IEEE International Conference on Data Mining. IEEE, 869–874"	458	hort	post-processing	classifier	decision_tree
187	"Faisal Kamiran, Asim Karim, and Xiangliang Zhang. 2012. Decision theory for discrimination-aware classification. In Proceedings of the IEEE 12th International Conference on Data Mining. IEEE, 924–929"	458	hort	post-processing	output	boundary
188	"Faisal Kamiran, Sameen Mansha, Asim Karim, and Xiangliang Zhang. 2018. Exploiting reject option in classification for social discrimination control. Inf. Sci. 425 (2018), 18–33."	62	hort	post-processing	output	boundary
189	"Toshihiro Kamishima, Shotaro Akaho, Hideki Asoh, and Jun Sakuma. 2012. Fairness-aware classifier with prejudice remover regularizer. In Proceedings of the Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 35–50."	1025	hort	in-processing	regularisation	l2_regression
190	"Toshihiro Kamishima, Shotaro Akaho, Hideki Asoh, and Jun Sakuma. 2013. The independence of fairness-aware classifiers. In Proceedings of the IEEE 13th International Conference on Data Mining Workshops. IEEE, 849–858."	17	hort	in-processing	adjusted	bayesian
191	"Toshihiro Kamishima, Shotaro Akaho, Hideki Asoh, and Jun Sakuma. 2018. Model-based and actual independence for fairness-aware classification. Data Min. Knowl. Discov. 32, 1 (2018), 258–286"	27	hort	in-processing	adjusted	
192	"Toshihiro Kamishima, Shotaro Akaho, and Jun Sakuma. 2011. Fairness-aware learning through regularization approach. In Proceedings of the IEEE 11th International Conference on Data Mining Workshops. IEEE, 643–650."	543	hort	in-processing	regularisation	l2_regression
193	"Kentaro Kanamori and Hiroki Arimura. 2019. Fairness-aware edit of thresholds in a learned decision tree using a mixed integer programming formulation. In Proceedings of the 33rd Annual Conference of the Japanese Society for Artificial Intelligence. The Japanese Society for Artificial Intelligence, 3Rin211–3Rin211."	4	hort	post-processing	classifier	
194	"Kentaro Kanamori and Hiroki Arimura. 2021. Fairness-aware decision tree editing based on mixed-integer linear optimization. Trans. Japan. Societ. Artif. Intell. 36, 4 (2021), B–L13_1"	7	hort	post-processing	classifier	decision_tree
195	"Jian Kang, Tiankai Xie, Xintao Wu, Ross Maciejewski, and Hanghang Tong. 2021. MultiFair: Multi-group fairness in machine learning. arXiv"	21	hort	in-processing	regularisation	intersectional
196	"Michael Kearns, Seth Neel, Aaron Roth, and Zhiwei Steven Wu. 2018. Preventing fairness gerrymandering: Auditing and learning for subgroup fairness. InProceedings of Machine Learning Research, Vol. 80, Jennifer Dy and Andreas Krause (Eds.)."	924	hort	in-processing	adversarial	intersectional
197	"Thomas Kehrenberg, Zexun Chen, and Novi Quadrianto. 2019. Tuning fairness by marginalizing latent target labels. stat 1050 (2019), 10."	3	hort			
198	"Thomas Kehrenberg, Zexun Chen, and Novi Quadrianto. 2020. Tuning fairness by balancing target labels. Front. Artif. Intell. 3 (2020), 33."	20	hort	pre-processing	latent	latent_groupmembership
199	"Kamrun Naher Keya, Rashidul Islam, Shimei Pan, Ian Stockwell, and James R. Foulds. 2020. Equitable allocation of healthcare resources with fair Cox models. arXiv preprint arXiv:2010.06820 (2020)."	28	hort	in-processing	regularisation	
200	"Niki Kilbertus, Adrià Gascón, Matt Kusner, Michael Veale, Krishna Gummadi, and Adrian Weller. 2018. Blind justice: Fairness with encrypted sensitive attributes. In Proceedings of the International Conference on Machine Learning. PMLR, 2630–2639."	172	hort	in-processing	adjusted	lr
201	"Niki Kilbertus, Manuel Gomez Rodriguez, Bernhard Schölkopf, Krikamol Muandet, and Isabel Valera. 2020. Fair decisions despite imperfect predictions. In Proceedings of the International Conference on Artificial Intelligence and Statistics. PMLR, 277–287"	69	hort	in-processing	adjusted	
202	"Niki Kilbertus, Mateo Rojas-Carulla, Giambattista Parascandolo, Moritz Hardt, Dominik Janzing, and Bernhard Schölkopf. 2017. Avoiding discrimination through causal reasoning. In Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS’17). Curran Associates Inc., Red Hook, NY, 656666."	725	hort	in-processing	constraints	latent_groupmembership
203	"Joon Sik Kim, Jiahao Chen, and Ameet Talwalkar. 2020. Fact: A diagnostic for group fairness trade-offs. In Proceedings of the International Conference on Machine Learning. PMLR, 5264–5274."	57	hort	post-processing	classifier	
204	Jin-Young Kim and Sung-Bae Cho. 2020. Fair representation for safe artificial intelligence via adversarial learning of unbiased information bottleneck. In Proceedings of the Workshop on Artificial Intelligence and Safety (SafeAI@AAAI’20). 105–112	20	hort	pre-processing	representation	adversarial
205	"Jin-Young Kim and Sung-Bae Cho. 2022. An information theoretic approach to reducing algorithmic bias for machine learning. Neurocomputing 500 (2022), 26–38."	21	hort	in-processing	regularisation	
206	"Michael Kim, Omer Reingold, and Guy Rothblum. 2018. Fairness through computationally-bounded awareness. Adv. Neural Inf. Process. Syst. 31"	180	hort	post-processing	output	individual_fairness
207	"Michael P. Kim, Amirata Ghorbani, and James Zou. 2019. Multiaccuracy: Black-box post-processing for fairness in classification. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. 247–254."	385	hort	post-processing	classifier	boosting
208	"Kenji Kobayashi and Yuri Nakao. 2021. One-vs.-one mitigation of intersectional bias: A general method for extending fairness-aware binary classification. In Proceedings of the International Conference on Disruptive Technologies, Tech Ethics and Artificial Intelligence. Springer, 43–54."	11	hort	post-processing	output	group_dependent
209	Junpei Komiyama and Hajime Shimao. 2017. Two-stage algorithm for fairness-aware machine learning. arXiv preprint arXiv:1710.04924 (2017)	23	hort	in-processing	constraints	residuals
210	"Junpei Komiyama, Akiko Takeda, Junya Honda, and Hajime Shimao. 2018. Nonconvex optimization for regression with fairness constraints. In Proceedings of the International Conference on Machine Learning. PMLR, 2737–2746"	130	hort	in-processing	constraints	intersectional
211	"Emmanouil Krasanakis, Eleftherios Spyromitros-Xioufis, Symeon Papadopoulos, and Yiannis Kompatsiaris. 2018. Adaptive sensitive reweighting to mitigate bias in fairness-aware classification. In Proceedings of the World Wide Web Conference. 853–862"	181	hort	pre-processing	sampling	reweighing
212	"Caitlin Kuhlman, Latifa Jackson, and Rumi Chunara. 2020. No computation without representation: Avoiding data and algorithm biases through diversity. arXiv preprint arXiv:2002.11836 (2020)."	47	hort			
213	"Matt J. Kusner, Joshua Loftus, Chris Russell, and Ricardo Silva. 2017. Counterfactual fairness. In Proceedings of the International Conference on Advances in Neural Information Processing Systems. 4066–4076."	2098	hort	in-processing	adjusted	
214	"Preethi Lahoti, Alex Beutel, Jilin Chen, Kang Lee, Flavien Prost, Nithum Thain, Xuezhi Wang, and Ed Chi. 2020. Fairness without demographics through adversarially reweighted learning. Adv. Neural Inf. Process. Syst. 33 (2020), 728–74"	352	hort	in-processing	adversarial	adversarial_reweighted
215	"Preethi Lahoti, Krishna P. Gummadi, and Gerhard Weikum. 2019. iFair: Learning individually fair data representations for algorithmic decision making. In Proceedings of the IEEE 35th International Conference on Data Engineering (ICDE’19). IEEE, 1334–1345."	204	hort	pre-processing	representation	optimisation
216	"Preethi Lahoti, Krishna P. Gummadi, and Gerhard Weikum. 2019. Operationalizing individual fairness with pairwise fair representations. Proc. VLDB Endow. 13, 4 (Dec.2019), 506518"	121	hort	pre-processing	representation	optimisation
217	"Alex Lamy, Ziyuan Zhong, Aditya K. Menon, and Nakul Verma. 2019. Noise-tolerant fair classification. Adv. Neural Inf. Process. Syst. 32 (2019)."	93	hort	in-processing	constraints	
218	"Connor Lawless, Sanjeeb Dash, Oktay Gunluk, and Dennis Wei. 2021. Interpretable and fair Boolean rule sets via column generation. arXiv preprint arXiv:2111.08466 (2021)."	14	hort	in-processing	constraints	
219	"Tai Le Quy, Arjun Roy, Vasileios Iosifidis, Wenbin Zhang, and Eirini Ntoutsi. 2022. A survey on datasets for fairnessaware machine learning. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 12, 3 (2022), e1452"	263	hort			
220	"Joshua Lee, Yuheng Bu, Prasanna Sattigeri, Rameswar Panda, Gregory Wornell, Leonid Karlinsky, and Rogerio Feris. 2022. A maximal correlation approach to imposing fairness in machine learning. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP’22). IEEE, 3523–3527."	13	hort	in-processing	regularisation	
221	"Joshua Lee, Yuheng Bu, Prasanna Sattigeri, Rameswar Panda, Gregory W. Wornell, Leonid Karlinsky, and Rogerio Schmidt Feris. 2022. A maximal correlation framework for fair machine learning. Entropy 24, 4 (2022), 461."	7	hort	in-processing	regularisation	
222	"Joshua K. Lee, Yuheng Bu, Deepta Rajan, Prasanna Sattigeri, Rameswar Panda, Subhro Das, and Gregory W. Wornell. 2021. Fair selective classification via sufficiency. In Proceedings of the International Conference on Machine Learning. PMLR, 6076–6086."	26	hort	in-processing	adjusted	
223	Michelle Seng Ah Lee and Jat Singh. 2021. The landscape and gaps in open source fairness toolkits. In Proceedings of the CHI Conference on Human Factors in Computing Systems. 1–13.	145	hort			
224	"Chenglu Li, Wanli Xing, and Walter Leite. 2021. Yet another predictive model? Fair predictions of students’ learning outcomes in an online math learning platform. In Proceedings of the 11th International Learning Analytics and Knowledge Conference (LAK’21). 572–578."	24	hort	in-processing	constraints	
225	"Peizhao Li and Hongfu Liu. 2022. Achieving fairness at no utility cost via data reweighing with influence. In Proceedings of the International Conference on Machine Learning. PMLR, 12917–12930"	62	hort	pre-processing	sampling	reweighing
226	"Tianyi Li, Zhoufei Tang, Tao Lu, and Xiaoquan Michael Zhang. 2022. “Propose and review”: Interactive bias mitigation for machine classifiers. Retrieved from: SSRN 4139244 (2022)."	7	hort	pre-processing	relabelling	perturbation
227	"Xinyue Li, Zhenpeng Chen, Jie M. Zhang, Federica Sarro, Ying Zhang, and Xuanzhe Liu. 2023. Dark-skin individuals are at more risk on the street: Unmasking fairness issues of autonomous driving systems. CoRR abs/2308.02935 (2023)."	6	hort			
228	"Xuran Li, Peng Wu, and Jing Su. 2022. Accurate fairness: Improving individual fairness without trading accuracy. arXiv preprint arXiv:2205.08704 (2022)."	19	hort	in-processing	adjusted	
229	"Yanhui Li, Linghan Meng, Lin Chen, Li Yu, Di Wu, Yuming Zhou, and Baowen Xu. 2022. Training data debugging for the fairness of machine learning software. In Proceedings of the IEEE/ACM 44th International Conference on Software Engineering (ICSE’22). 2215–2227. DOI"	49	hort	post-processing	input	perturbation
230	"Yueqing Liang, Canyu Chen, Tian Tian, and Kai Shu. 2022. Joint adversarial learning for cross-domain fair classification. arXiv preprint arXiv:2206.03656 (2022"	4	hort	in-processing	adversarial	latent_groupmembership
231	"Jixue Liu, Jiuyong Li, Lin Liu, Thuc Duy Le, Feiyue Ye, and Gefei Li. 2018. FairMod-making predictive models discrimination aware. arXiv preprint arXiv:1811.01480 (2018"	3	hort	post-processing	output	
232	"Shaofan Liu, Shiliang Sun, and Jing Zhao. 2022. Fair transfer learning with factor variational auto-encoder. Neural Processing Letters55 (2022), 2049–2061. https://api.semanticscholar.org/CorpusID:249702782"	6	hort	pre-processing	representation	vaes
233	"Suyun Liu and Luis Nunes Vicente. 2022. Accuracy and fairness trade-offs in machine learning: A stochasticmulti-objective approach. Computational Management Science 19, 3 (2022), 513–537."	86	hort	in-processing	compositionnal	pareto
234	"Wenyan Liu, Xiangfeng Wang, Xingjian Lu, Junhong Cheng, Bo Jin, Xiaoling Wang, and Hongyuan Zha. 2021. Fair Differential Privacy Can Mitigate the Disparate Impact on Model Accuracy. Retrieved from https://openreview.net/forum?id=IqVB8e0DlUd"	7	hort	in-processing	adjusted	
235	"Michael Lohaus, Michaël Perrot, and Ulrike Von Luxburg. 2020. Too relaxed to be fair. In Proceedings of the International Conference on Machine Learning. PMLR, 6360–6369"	74	hort	in-processing	constraints	
236	Pranay Lohia. 2021. Priority-based post-processing bias mitigation for individual and group fairness. arXiv preprint arXiv:2102.00417(2021	13	hort	post-processing	output	
237	"Pranay K. Lohia, Karthikeyan Natesan Ramamurthy, Manish Bhide, Diptikalyan Saha, Kush R. Varshney, and Ruchir Puri. 2019. Bias mitigation post-processing for individual and group fairness. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP’19). 2847–2851."	209	hort	post-processing	output	boundary
238	"Christos Louizos, Kevin Swersky, Yujia Li, Max Welling, and Richard S. Zemel. 2016. The variational fair autoencoder. In Proceedings of the 4th International Conference on Learning Representations (ICLR’16), Yoshua Bengio and Yann LeCun (Eds.). Retrieved from http://arxiv.org/abs/1511.00830"	749	hort	pre-processing	representation	vaes
239	"Andrew Lowy, Rakesh Pavan, Sina Baharlouei, Meisam Razaviyayn, and Ahmad Beirami. 2021. FERMI: Fair empirical risk minimization via exponential Rényi mutual information. arXiv preprint arXiv:2102.12586 (2021)."	15	hort	in-processing	regularisation	
240	Kristian Lum and James Johndrow. 2016. A statistical framework for fair predictive algorithms. arXiv preprint arXiv:1610.08077 (2016).	124	hort	pre-processing	relabelling	perturbation
241	"Ling Luo, Wei Liu, Irena Koprinska, and Fang Chen. 2015. Discrimination-aware association rule mining for unbiased data analytics. In Proceedings of the International Conference on Big Data Analytics and Knowledge Discovery. Springer, 108–120"	15	hort	in-processing	adjusted	
242	"Binh Thanh Luong, Salvatore Ruggieri, and Franco Turini. 2011. k-NN as an implementation of situation testing for discrimination discovery and prevention. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 502–510."	258	hort	pre-processing	relabelling	massaging
243	Ramanujam Madhavan and Mohit Wadhwa. 2020. Fairness-aware learning with prejudice free representations. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management. 2137–2140.	9	hort	pre-processing	representation	removal_features
244	"David Madras, Elliot Creager, Toniann Pitassi, and Richard Zemel. 2018. Learning adversarially fair and transferable representations. In Proceedings of the International Conference on Machine Learning. PMLR, 3384–3393"	766	hort	pre-processing	representation	adversarial
245	"David Madras, Elliot Creager, Toniann Pitassi, and Richard Zemel. 2019. Fairness through causal awareness: Learning causal latent-variable models for biased data. In Proceedings of the Conference on Fairness, Accountability, and Transparency. 349–358"	174	hort	in-processing	adjusted	latent_groupmembership
246	"David Madras, Toni Pitassi, and Richard Zemel. 2018. Predict responsibly: Improving fairness and accuracy by learning to defer. Adv. Neural Inf. Process. Syst. 31 (2018)."	246	hort	in-processing	adjusted	rejection_learning
247	Gaurav Maheshwari and Michaël Perrot. 2022. FairGrad: Fairness aware gradient descent. arXiv preprint arXiv:2206.10923 (2022).	17	hort	in-processing	adjusted	
248	"ubha Maity, Debarghya Mukherjee, Mikhail Yurochkin, and Yuekai Sun. 2020. There is no trade-off: Enforcing fairness can improve accuracy. arXiv preprint arXiv:2011.03173 (2020)"	11	hort	in-processing	constraints	
249	"Debmalya Mandal, Samuel Deng, Suman Jana, Jeannette Wing, and Daniel J. Hsu. 2020. Ensuring fairness beyond the training data. Adv. Neural Inf. Process. Syst. 33 (2020), 18445–18456."	64	hort	in-processing	adjusted	
250	"Ricards Marcinkevics, Ece Ozkan, and Julia E. Vogt. 2022. Debiasing deep chest x-ray classifiers using intra- and post-processing methods. In Proceedings of the Machine Learning for Healthcare Conference. PMLR."	28	hort	post-processing	classifier	nn
251	"William Martin, Federica Sarro, Yue Jia, Yuanyuan Zhang, and Mark Harman. 2016. A survey of app store analysis for software engineering. IEEE Trans. Softw. Eng. 43, 9 (2016), 817–847."	558	hort			
252	"Natalia Martinez, Martin Bertran, and Guillermo Sapiro. 2020. Minimax Pareto fairness: A multi objective perspective. In Proceedings of the International Conference on Machine Learning. PMLR, 6755–6764."	230	hort	in-processing	adjusted	ap_star
253	"Jérémie Mary, Clément Calauzenes, and Noureddine El Karoui. 2019. Fairness-aware learning for continuous attributes and treatments. In Proceedings of the International Conference on Machine Learning. PMLR, 4382–4391."	139	hort	in-processing	regularisation	
254	"Daniel McNamara, Cheng Soon Ong, and Robert C. Williamson. 2017. Provably fair representations. arXiv preprint arXiv:1710.04394(2017)."	62	hort	pre-processing	representation	optimisation
255	"Ninareh Mehrabi, Umang Gupta, Fred Morstatter, Greg Ver Steeg, and Aram Galstyan. 2022. Attributing fair decisions with attention interventions. In Proceedings of the 2nd Workshop on Trustworthy Natural Language Processing (TrustNLP’22). Association for Computational Linguistics, 12–25. DOI:"	32	hort	post-processing	classifier	nn
256	"Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. 2021. A survey on bias and fairness in machine learning. ACM Comput. Surv. 54, 6 (2021), 1–35."	5057	hort			
257	"Aditya Krishna Menon and Robert C. Williamson. 2018. The cost of fairness in binary classification. In Proceedings of the Conference on Fairness, Accountability and Transparency. PMLR, 107–118."	507	hort	post-processing	output	plugin
258	Alan Mishler and Edward Kennedy. 2021. FADE: FAir double ensemble learning for observable and counterfactual outcomes. arXiv preprint arXiv:2109.00173 (2021).	22	hort	post-processing	classifier	pareto
259	"Alan Mishler, Edward H. Kennedy, and Alexandra Chouldechova. 2021. Fairness in risk assessment instruments: Post-processing to achieve counterfactual equalized odds. In Proceedings of the ACM Conference on Fairness, Accountability, and Transparency (FAccT’21). Association for Computing Machinery, New York, NY, 386400. DOI:"	84	hort	post-processing	classifier	equal_odds
260	"Kiarash Mohammadi, Aishwarya Sivaraman, and Golnoosh Farnadi. 2022. FETA: Fairness enforced verifying, training, and predicting algorithms for neural networks. arXiv preprint arXiv:2206.00553 (2022)."	6	hort	post-processing	output	
261	Wellington Rodrigo Monteiro and Gilberto Reynoso-Meza. [n.d.]. Proposal of a fair voting classifier using multi-objective optimization. 	2	hort	in-processing		ensemble
262	Wellington Rodrigo Monteiro and Gilberto Reynoso-Meza. 2021. Proposal of a Fair Voting Classifier Using Multi-Objective Optimization.	2	hort	in-processing	compositionnal	
263	Alice Morano. 2020. Bias Mitigation for Automated Decision Making Systems. Ph. D. Dissertation. Politecnico di Torino	5	hort	pre-processing	sampling	smote_like
264	"Giulio Morina, Viktoriia Oliinyk, Julian Waton, Ines Marusic, and Konstantinos Georgatzis. 2019. Auditing and achieving intersectional fairness in classification problems. arXiv preprint arXiv:1911.01468 (2019)."	40	hort	post-processing	classifier	equal_odds
265	"Sérgio Moro, Paulo Cortez, and Paulo Rita. 2014. A data-driven approach to predict the success of bank telemarketing. Decis. Supp. Syst. 62 (2014), 22–31"	1171	hort			
266	"Daniel Moyer, Shuyang Gao, Rob Brekelmans, Greg Ver Steeg, and Aram Galstyan. 2018. Invariant representations without adversarial training. In Proceedings of the 32nd International Conference on Neural Information Processing Systems. 9102–9111."	246	hort	pre-processing	representation	optimisation
267	"Razieh Nabi, Daniel Malinsky, and Ilya Shpitser. 2019. Learning optimal fair policies. In Proceedings of the International Conference on Machine Learning. PMLR, 4674–4682"	114	hort	in-processing	constraints	
268	"Razieh Nabi and Ilya Shpitser. 2018. Fair inference on outcomes. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 32."	413	hort	in-processing	constraints	
269	"Harikrishna Narasimhan. 2018. Learning with complex loss functions and constraints. In Proceedings of the International Conference on Artificial Intelligence and Statistics. PMLR, 1646–1654"	111	hort	in-processing	constraints	
270	"Dang Nguyen, Sunil Gupta, Santu Rana, Alistair Shilton, and Svetha Venkatesh. 2021. Fairness improvement for black-box classifiers with Gaussian process. Inf. Sci. 576 (2021), 542–556"	18	hort	post-processing	output	
271	"Alejandro Noriega-Campero, Michiel A. Bakker, Bernardo Garcia-Bulle, and Alex “Sandy” Pentland. 2019. Active fairness in algorithmic decision making. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. 77–83"	107	hort	post-processing	classifier	split_clf
272	"Ziad Obermeyer, Brian Powers, Christine Vogeli, and Sendhil Mullainathan. 2019. Dissecting racial bias in an algorithm used to manage the health of populations. Science 366, 6464 (2019), 447–453"	4440	hort			
273	"Changdae Oh, Heeji Won, Junhyuk So, Taero Kim, Yewon Kim, Hosik Choi, and Kyungwoo Song. 2022. Learning fair representation via distributional contrastive disentanglement. arXiv preprint arXiv:2206.08743 (2022)."	22	hort	pre-processing	representation	vaes
274	"Mahbod Olfat and Anil Aswani. 2018. Spectral algorithms for computing fair support vector machines. In Proceedings of the International Conference on Artificial Intelligence and Statistics. PMLR, 1933–1942"	36	hort	in-processing	constraints	
275	"Luca Oneto, Michele Donini, and Massimiliano Pontil. 2020. General fair empirical risk minimization. In Proceedings of the International Joint Conference on Neural Networks (IJCNN’20). IEEE, 1–8."	55	hort	in-processing	constraints	
276	"Luca Oneto, Michele Doninini, Amon Elders, and Massimiliano Pontil. 2019. Taking advantage of multitask learning for fair classification. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. 227–"	83	hort	in-processing	compositionnal	different_clf
277	"Mustafa Safa Ozdayi, Murat Kantarcioglu, and Rishabh Iyer. 2021. BiFair: Training fair models with bilevel optimization. arXiv preprint arXiv:2106.04757 (2021"	8	hort	in-processing	adjusted	
278	Manisha Padala and Sujit Gujar. 2020. FNNC: Achieving fairness through neural networks. In Proceedings of the 29th International Joint Conference on Artificial Intelligence (IJCAI’20). International Joint Conferences on Artificial Intelligence Organization	72	hort	in-processing	constraints	
279	"Kirtan Padh, Diego Antognini, Emma Lejal-Glaude, Boi Faltings, and Claudiu Musat. 2021. Addressing fairness in classification with a model-agnostic multi-objective algorithm. In Uncertainty in Artificial Intelligence. PMLR, 600–609."	33	hort	in-processing	constraints	intersectional
280	"Saerom Park, Junyoung Byun, and Joohee Lee. 2022. Privacy-preserving fair learning of support vector machine with homomorphic encryption. In Proceedings of the ACM Web Conference (WWW’22). Association for Computing Machinery, New York, NY, 35723583. DOI"	23	hort	in-processing	adjusted	
281	"Pranita Patil and Kevin Purcell. 2022. Decorrelation-based deep learning for bias mitigation. Fut. Internet 14, 4 (2022), 110"	8	hort	in-processing	regularisation	
282	"Dino Pedreschi, Salvatore Ruggieri, and Franco Turini. 2009. Measuring discrimination in socially-sensitive decision records. In Proceedings of the SIAM International Conference on Data Mining. SIAM, 581–592."	244	hort	post-processing	output	confidence
283	"Dino Pedreshi, Salvatore Ruggieri, and Franco Turini. 2008. Discrimination-aware data mining. In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 560–568"	912	hort			
284	"Sikha Pentyala, Nicola Neophytou, Anderson Nascimento, Martine De Cock, and Golnoosh Farnadi. 2022. PrivFairFL: Privacy-preserving group fairness in federated learning. arXiv preprint arXiv:2205.11584 (2022)."	24	hort	post-processing	output	group_dependent
285	"Adrián Pérez-Suay, Valero Laparra, Gonzalo Mateo-García, Jordi Muñoz-Marí, Luis Gómez-Chova, and Gustau Camps-Valls. 2017. Fair kernel learning. In Proceedings of the Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 339–355"	104	hort	in-processing	regularisation	dim_reduction
286	"Valerio Perrone, Michele Donini, Muhammad Bilal Zafar, Robin Schmucker, Krishnaram Kenthapadi, and Cédric Archambeau. 2021. Fair Bayesian optimization. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. 854–863"	89	hort	in-processing	adjusted	hyperparameters_tuning
287	Dana Pessach and Erez Shmueli. 2020. Algorithmic fairness. arXiv preprint arXiv:2001.09784 (2020).	256	hort			
288	"Dana Pessach and Erez Shmueli. 2022. A review on fairness in machine learning. ACM Comput. Surv. 55, 3 (2022), 1–44."	491	hort			
289	"Andrija Petrović, Mladen Nikolić, Sandro Radovanović, Boris Delibašić, and Miloš Jovanović. 2022. FAIR: Fair adversarial instance re-weighting. Neurocomputing 476 (2022), 14–37."	35	hort	in-processing	adversarial	
290	"Andrija Petrović, Mladen Nikolić, Miloš Jovanović, Miloš Bijanić, and Boris Delibašić. 2021. Fair classification via Monte Carlo policy gradient method. Eng. Applic. Artif. Intell. 104 (2021), 104398"	11	hort	in-processing	constraints	
291	"Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, and Kilian Q. Weinberger. 2017. On fairness and calibration. In Proceedings of the International Conference on Advances in Neural Information Processing Systems. 5680–5689"	1059	hort	post-processing	classifier	split_clf
292	"Tao Qi, Fangzhao Wu, Chuhan Wu, Lingjuan Lyu, Tong Xu, Zhongliang Yang, Yongfeng Huang, and Xing Xie. 2022. FairVFL: A fair vertical federated learning framework with contrastive adversarial learning. arXiv preprint arXiv:2206.03200 (2022"	38	hort	pre-processing	representation	adversarial
293	"Shangshu Qian, Viet Hung Pham, Thibaud Lutellier, Zeou Hu, Jungwon Kim, Lin Tan, Yaoliang Yu, Jiahao Chen, and Sameena Shah. 2021. Are my deep learning systems fair? An empirical study of fixed-seed training. Adv. Neural Inf. Process. Syst. 34 (2021), 30211–30227"	47	hort			
294	"Novi Quadrianto and Viktoriia Sharmanska. 2017. Recycling privileged learning and distribution matching for fairness. Adv. Neural Inf. Process. Syst. 30 (2017), 677–688"	112	hort	in-processing	constraints	
295	"Novi Quadrianto, Viktoriia Sharmanska, and Oliver Thomas. 2018. Neural styling for interpretable fair representations. arXiv preprint arXiv:1810.06755 (2018)."	6	hort	pre-processing	representation	transfer
296	"Novi Quadrianto, Viktoriia Sharmanska, and Oliver Thomas. 2019. Discovering fair representations in the data domain. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 8227"	165	hort	pre-processing	representation	transfer
297	"Edward Raff and Jared Sylvester. 2018. Gradient reversal against discrimination: A fair neural network learning approach. In Proceedings of the IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA’18). IEEE, 189–198."	46	hort	in-processing	adjusted	nn
298	"Edward Raff, Jared Sylvester, and Steven Mills. 2018. Fair forests: Regularized tree induction to minimize model bias. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. 243–250."	87	hort	in-processing	regularisation	
299	"Amirarsalan Rajabi and Ozlem Ozmen Garibay. 2022. TabFairGan: Fair tabular data generation with generative adversarial networks. Mach. Learn. Knowl. Extract. 4, 2 (2022), 488–501"	65	hort	pre-processing	sampling	generative
300	"Francesco Ranzato, Caterina Urban, and Marco Zanella. 2021. Fairness-aware training of decision trees by abstract interpretation. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management. 1508–1517"	18	hort	in-processing	compositionnal	ensemble
301	"Miriam Rateike, Ayan Majumdar, Olga Mineeva, Krishna P. Gummadi, and Isabel Valera. 2022. Don’t throw it away! The utility of unlabeled data in fair decision making. In Proceedings of the ACM Conference on Fairness, Accountability, and Transparency. 1421–1433."	11	hort	in-processing	adjusted	vaes
302	"Srinivasan Ravichandran, Drona Khurana, Bharath Venkatesh, and Narayanan Unny Edakunni. 2020. FairXGBoost: Fairness-aware classification in XGBoost. arXiv preprint arXiv:2009.01442 (2020"	13	hort	in-processing	regularisation	
303	"Michael Redmond and Alok Baveja. 2002. A data-driven software tool for enabling cooperative information sharing among police departments. Eur. J. Oper. Res. 141, 3 (2002), 660–678"	301	hort			
304	"Ashkan Rezaei, Rizal Fathony, Omid Memarrast, and Brian Ziebart. 2020. Fairness for robust log loss classification. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 5511–5518"	74	hort	in-processing	adversarial	
305	"Ashkan Rezaei, Anqi Liu, Omid Memarrast, and Brian D. Ziebart. 2021. Robust fairness under covariate shift. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 9419–9427"	95	hort	in-processing	adversarial	
306	"Goce Ristanoski, Wei Liu, and James Bailey. 2013. Discrimination aware classification for imbalanced datasets. In Proceedings of the 22nd ACM International Conference on Information & Knowledge Management. 1529–1532"	47	hort	in-processing	regularisation	
307	"Yuji Roh, Kangwook Lee, Steven Whang, and Changho Suh. 2020. FR-Train: A mutual information-based approach to fair and robust training. In Proceedings of the International Conference on Machine Learning. PMLR, 8147–8157"	96	hort	in-processing	adversarial	
308	"Yuji Roh, Kangwook Lee, Steven Euijong Whang, and Changho Suh. 2021. FairBatch: Batch selection for model fairness. In Proceedings of the 9th International Conference on Learning Representations (ICLR’21)."	144	hort	in-processing	adjusted	lr
309	"Yuji Roh, Kangwook Lee, Steven Euijong Whang, and Changho Suh. 2021. Sample selection for fair and robust training. In Proceedings of the 35th Conference on Neural Information Processing Systems"	71	hort	pre-processing	sampling	downsampling
310	"Yaniv Romano, Stephen Bates, and Emmanuel Candes. 2020. Achieving equalized odds by resampling sensitive attributes. Adv. Neural Inf. Process. Syst. 33 (2020), 361–371"	48	hort	in-processing	regularisation	
311	"Andrea Romei and Salvatore Ruggieri. 2014. A multidisciplinary survey on discrimination analysis. The Knowledge Engineering Review29, 5 (2014), 582–638"	380	hort			
312	"Arjun Roy, Vasileios Iosifidis, and Eirini Ntoutsi. 2022. Multi-fair Pareto boosting. In Proceedings of the International Conference on Discovery Science. Springer"	9	hort	in-processing	adjusted	boosting
313	Arjun Roy and Eirini Ntoutsi. 2022. Learning to teach fairness-aware deep multi-task learning. In Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases	11	hort	in-processing	adjusted	
314	"Anian Ruoss, Mislav Balunovic, Marc Fischer, and Martin Vechev. 2020. Learning certified individually fair representations. Adv. Neural Inf. Process. Syst. 33 (2020), 7584–7596"	101	hort	pre-processing	representation	adversarial
315	"Chris Russell, M. Kusner, C. Loftus, and Ricardo Silva. 2017. When worlds collide: Integrating different counterfactual assumptions in fairness. In Proceedings of the International Conference on Advances in Neural Information Processing Systems, Vol. 30. NIPS Proceedings"	215	hort	in-processing	constraints	
316	"Bashir Sadeghi, Runyi Yu, and Vishnu Boddeti. 2019. On the global optima of kernelized adversarial representation learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 7971–7979"	36	hort	in-processing	adversarial	nn
317	"Ricardo Salazar, Felix Neutatz, and Ziawasch Abedjan. 2021. Automated feature engineering for algorithmic fairness. Proc. VLDB Endow. 14, 9 (2021), 1694–1702."	36	hort	pre-processing	representation	addition_features
318	"Teresa Salazar, Miriam Seoane Santos, Helder Araújo, and Pedro Henriques Abreu. 2021. Fawos: Fairness-awareoversampling algorithm based on distributions of sensitive attributes. IEEE Access 9 (2021), 81370–81379"	24	hort	pre-processing	sampling	smote_like
319	"Babak Salimi, Luke Rodriguez, Bill Howe, and Dan Suciu. 2019. Interventional fairness: Causal database repair for algorithmic fairness. In Proceedings of the International Conference on Management of Data. 793–810"	215	hort	pre-processing	sampling	downsampling
320	"Samira Samadi, Uthaipon Tantipongpipat, Jamie H. Morgenstern, Mohit Singh, and Santosh Vempala. 2018. The price of fair PCA: One extra dimension. In Proceedings of the International Conference on Advances in Neural Information Processing Systems. 10976–10987"	175	hort	pre-processing	representation	dim_reduction
321	"Mhd Hasan Sarhan, Nassir Navab, Abouzar Eslami, and Shadi Albarqouni. 2020. Fairness by learning orthogonal disentangled representations. In Proceedings of the European Conference on Computer Vision. Springer, 746–761"	98	hort	pre-processing	representation	
322	Federica Sarro. 2023. Search-based software engineering in the era of modern software systems. In Proceedings of the 31st IEEE International Requirements Engineering Conference	12	hort			
323	"Yash Savani, Colin White, and Naveen Sundar Govindarajulu. 2020. Intra-processing methods for debiasing neural networks. Adv. Neural Inf. Process. Syst. 33 (2020), 2798–2810."	55	hort	post-processing	classifier	nn
324	"Nicolas Schreuder and Evgenii Chzhen. 2021. Classification with abstention but without disparities. In Uncertainty in Artificial Intelligence. PMLR, 1227–1236"	32	hort	post-processing	classifier	
325	"Marco Scutari, Francesca Panero, and Manuel Proissl. 2021. Achieving fairness with a simple ridge penalty. arXiv preprint arXiv:2105.13817 (2021"	15	hort	in-processing	constraints	
326	"Emel Seker, John R. Talburt, and Melody L. Greer. 2022. Preprocessing to address bias in healthcare data. Stud. Health Technol. Inform. 294 (2022), 327–331"	17	hort	pre-processing	relabelling	
327	"Shubham Sharma, Alan H. Gee, David Paydarfar, and Joydeep Ghosh. 2021. FaiR-N: Fair and robust neural networks for structured data. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society (AIES’21). Association for Computing Machinery, New York, NY, 946955"	22	hort	in-processing	adjusted	
328	"Shubham Sharma, Yunfeng Zhang, Jesús M. Ríos Aliaga, Djallel Bouneffouf, Vinod Muthusamy, and Kush R. Varshney. 2020. Data augmentation for discrimination prevention and bias disambiguation. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. 358–364"	108	hort	pre-processing	sampling	generative
329	Martin B. Short and George O. Mohler. 2022. A fully Bayesian tracking algorithm for mitigating disparate prediction misclassification. Int. J. Forecast. (2022	6	hort	in-processing	adjusted	
330	"Changjian Shui, Qi Chen, Jiaqi Li, Boyu Wang, and Christian Gagné. 2022. Fair representation learning through implicit path alignment. arXiv preprint arXiv:2205.13316"	22	hort	pre-processing	representation	optimisation
331	"Sandipan Sikdar, Florian Lemmerich, and Markus Strohmaier. 2022. GetFair: Generalized fairness tuning of classification models. In Proceedings of the ACM Conference on Fairness, Accountability, and Transparency"	16	hort	in-processing	adjusted	
332	"Arashdeep Singh, Jashandeep Singh, Ariba Khan, and Amar Gupta. 2022. Developing a novel fair-loan classifier through a multi-sensitive debiasing pipeline: DualFair. Mach. Learn. Knowl. Extract. 4, 1 (2022), 240–253"	14	hort	pre-processing	sampling	smote_like
333	Agnieszka Słowik and Léon Bottou. 2021. Algorithmic bias and data bias: Understanding the relation between distributionally robust optimization and data curation. arXiv preprint arXiv:2106.09467 (2021	25	hort	in-processing	constraints	
334	P. Snel and S. van Otterloo. 2022. Practical bias correction in neural networks: A credit default prediction case study. Comput. Societ. Res. J.3 (2022	4	hort	post-processing	output	
335	"Jiaming Song, Pratyusha Kalluri, Aditya Grover, Shengjia Zhao, and Stefano Ermon. 2019. Learning controllable fair representations. In Proceedings of the 22nd International Conference on Artificial Intelligence and Statistics. PMLR, 2164–2173."	207	hort	pre-processing	representation	optimisation
336	"Ezekiel Soremekun, Mike Papadakis, Maxime Cordy, and Yves Le Traon. 2022. Software fairness: An analysis and survey. arXiv preprint arXiv:2205.08809 (2022"	18	hort			
337	"Haipei Sun, Kun Wu, Ting Wang, and Wendy Hui Wang. 2022. Towards fair and robust classification. In Proceedings of the IEEE 7th European Symposium on Security and Privacy (EuroS&P’22). IEEE, 356–376."	13	hort	in-processing	regularisation	
338	"Tony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang, Mai ElSherief, Jieyu Zhao, Diba Mirza, Elizabeth Belding, Kai-Wei Chang, and William Yang Wang. 2019. Mitigating gender bias in natural language processing: Literature review. arXiv preprint arXiv:1906.08976(2019"	692	hort			
339	Supreme Court of the United States. 2009. Ricci v. DeStefanoo. Vol. 557.	X	hort			
340	"Vinith M. Suriyakumar, Marzyeh Ghassemi, and Berk Ustun. 2022. When personalization harms: Reconsidering the use of group attributes in prediction. arXiv preprint arXiv:2206.02058 (2022"	20	hort	in-processing	compositionnal	different_clf
341	"Jared Sylvester and Edward Raff. 2020. Trimming the thorns of AI fairness research. IEEE Data Eng. Bull. 43, 4 (2020), 74–84."	4	hort			
342	"Zilong Tan, Samuel Yeom, Matt Fredrikson, and Ameet Talwalkar. 2020. Learning fair representations for kernel models. In Proceedings of the International Conference on Artificial Intelligence and Statistics. PMLR, 155–166"	38	hort	pre-processing	representation	dim_reduction
343	"Guanhong Tao, Weisong Sun, Tingxu Han, Chunrong Fang, and Xiangyu Zhang. 2022. RULER: Discriminative and iterative adversarial training for deep neural network fairness. In Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE’22)"	22	hort	in-processing	adversarial	
344	Maryam Tavakol. 2020. Fair classification with counterfactual learning. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2073–2076	12	hort	in-processing	regularisation	intersectional
345	"Saeid Tizpaz-Niari, Ashish Kumar, Gang Tan, and Ashutosh Trivedi. 2022. Fairness-aware configuration of machine learning libraries. In Proceedings of the 44th International Conference on Software Engineering (ICSE’22). Association for Computing Machinery, 909920"	49	hort	in-processing	adjusted	hyperparameters_tuning
346	"Berk Ustun, Yang Liu, and David Parkes. 2019. Fairness without harm: Decoupled classifiers with preference guarantees. In Proceedings of the International Conference on Machine Learning. PMLR, 6373–6382"	149	hort	in-processing	compositionnal	transfer
347	"Ana Valdivia, Javier Sánchez-Monedero, and Jorge Casillas. 2021. How fair can we go in machine learning? Assessing the boundaries of accuracy and fairness. Int. J. Intell. Syst. 36, 4 (2021), 1619–1643."	62	hort	in-processing	adjusted	hyperparameters_tuning
348	"Benjamin van Giffen, Dennis Herhausen, and Tobias Fahse. 2022. Overcoming the pitfalls and perils of algorithms: A classification of machine learning biases and mitigation methods. J. Bus. Res. 144 (2022), 93–106."	160	hort			
349	"Sahil Verma, Michael Ernst, and Rene Just. 2021. Removing biased data to improve fairness and accuracy. arXiv preprint arXiv:2102.03054 (2021)."	28	hort	pre-processing	sampling	downsampling
350	"Sahil Verma and Julia Rubin. 2018. Fairness definitions explained. In Proceedings of the IEEE/ACM International Workshop on Software Fairness (FairWare’18). IEEE, 1–7"	1410	hort			
351	"Christina Wadsworth, Francesca Vera, and Chris Piech. 2018. Achieving fairness through adversarial learning: An application to recidivism prediction. arXiv preprint arXiv:1807.00199 (2018"	214	hort	in-processing	adversarial	
352	"Mingyang Wan, Daochen Zha, Ninghao Liu, and Na Zou. 2022. In-processing modeling techniques for machine learning fairness: A survey. ACM Trans. Knowl. Discov. Data (Jul.2022). DOI:"	122	hort			
353	"Guanchu Wang, Mengnan Du, Ninghao Liu, Na Zou, and Xia Hu. 2022. Mitigating algorithmic bias with limited annotations. arXiv preprint arXiv:2207.10018 (2022)."	8	hort	in-processing	adjusted	
354	"Hao Wang, Berk Ustun, and Flavio Calmon. 2019. Repairing without retraining: Avoiding disparate impact with counterfactual distributions. In Proceedings of the International Conference on Machine Learning. PMLR, 6618–6627"	91	hort	pre-processing	relabelling	perturbation
355	"Hao Wang, Berk Ustun, and Flavio P. Calmon. 2018. Avoiding disparate impact with counterfactual distributions. In Proceedings of the NeurIPS Workshop on Ethical, Social and Governance Issues in AI."	91	hort	pre-processing	relabelling	perturbation
356	"Jingbo Wang, Yannan Li, and Chao Wang. 2022. Synthesizing fair decision trees via iterative constraint solving. In Proceedings of the International Conference on Computer Aided Verification. Springer, 364–385."	15	hort	in-processing	constraints	decision_tree
357	"Jialu Wang, Yang Liu, and Caleb Levy. 2021. Fair classification with group-dependent label noise. In Proceedings of the ACM Conference on Fairness, Accountability, and Transparency. 526–536"	115	hort	in-processing	adjusted	
358	"Jialu Wang, Xin Eric Wang, and Yang Liu. 2022. Understanding instance-level impact of fairness constraints. In Proceedings of the 39th International Conference on Machine Learning(Proceedings of Machine Learning Research, Vol. 162), Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (Eds.). PMLR, 23114–23130. Retrieved from https://proceedings.mlr.press/v162/wang22ac.html"	33	hort	pre-processing	sampling	downsampling
359	"Serena Wang, Wenshuo Guo, Harikrishna Narasimhan, Andrew Cotter, Maya Gupta, and Michael Jordan. 2020. Robust optimization for fairness with noisy protected groups. Adv. Neural Inf. Process. Syst. 33 (2020), 5190–5203"	139	hort	in-processing	constraints	
360	Xiaoqian Wang and Heng Huang. 2019. Approaching machine learning fairness through adversarial network. arXiv preprint arXiv:1909.03013 (2019).	11	hort	pre-processing	representation	removal_features
361	"Yuyan Wang, Xuezhi Wang, Alex Beutel, Flavien Prost, Jilin Chen, and Ed H. Chi. 2021. Understanding and improving fairness-accuracy trade-offs in multi-task learning. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining. 1748–1757"	50	hort	in-processing	regularisation	
362	"Dennis Wei, Karthikeyan Natesan Ramamurthy, and Flavio du Pin Calmon. 2020. Optimized score transformation for fair classification. Proc. Mach. Learn. Res. 108 (2020"	49	hort	post-processing	output	latent_groupmembership
363	"Michael Wick, Swetasudha Panda, and Jean-Baptiste Tristan. 2019. Unlocking fairness: A trade-off revisited. In Proceedings of the NeurIPS Conference"	171	hort	in-processing	constraints	
364	Linda F. Wightman. 1998. LSAC national longitudinal bar passage study. LSAC research report series. (1998).	302	hort			
365	Claes Wohlin. 2014. Guidelines for snowballing in systematic literature studies and a replication in software engineering. In Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering. 1–10.	5248	hort			
366	"Blake Woodworth, Suriya Gunasekar, Mesrob I. Ohannessian, and Nathan Srebro. 2017. Learning non-discriminatory predictors. In Proceedings of the Conference on Learning Theory. PMLR, 1920–1953."	448	hort	post-processing	classifier	equal_odds
367	"Chuhan Wu, Fangzhao Wu, Tao Qi, and Yongfeng Huang. 2022. Semi-FairVAE: Semi-supervised fair representation learning with adversarial variational autoencoder. arXiv preprint arXiv:2204.00536 (2022"	5	hort	pre-processing	representation	adversarial_alone
368	"Songhua Wu, Mingming Gong, Bo Han, Yang Liu, and Tongliang Liu. 2022. Fair classification with instance-dependent label noise. In Proceedings of the Conference on Causal Learning and Reasoning. PMLR, 927–943."	30	hort	in-processing	constraints	
369	"Yongkai Wu, Lu Zhang, and Xintao Wu. 2018. Fairness-aware classification: Criterion, convexity, and bounds. arXiv preprint arXiv:1809.04737 (2018)."	24	hort	in-processing	constraints	
370	"Ziwei Wu and Jingrui He. 2022. Fairness-aware model-agnostic positive and unlabeled learning. In Proceedings of the ACM Conference on Fairness, Accountability, and Transparency (FAccT’22). Association for Computing Machinery, New York, NY, 16981708. DOI:"	15	hort	post-processing	classifier	
371	"Qizhe Xie, Zihang Dai, Yulun Du, Eduard Hovy, and Graham Neubig. 2017. Controllable invariance through adversarial feature learning. Adv. Neural Inf. Process. Syst. 30 (2017)."	307	hort	pre-processing	representation	adversarial
372	"Depeng Xu, Yongkai Wu, Shuhan Yuan, Lu Zhang, and Xintao Wu. 2019. Achieving causal fairness through generative adversarial networks. In Proceedings of the 28th International Joint Conference on Artificial Intelligence"	111	hort	pre-processing	sampling	generative
373	"Depeng Xu, Shuhan Yuan, and Xintao Wu. 2019. Achieving differential privacy and fairness in logistic regression. In Proceedings of the World Wide Web Conference. 594–599."	94	hort	in-processing	constraints	
374	"Depeng Xu, Shuhan Yuan, Lu Zhang, and Xintao Wu. 2018. FairGAN: Fairness-aware generative adversarial networks. In Proceedings of the IEEE International Conference on Big Data (Big Data’18). IEEE, 570–575"	357	hort	pre-processing	sampling	generative
375	"Depeng Xu, Shuhan Yuan, Lu Zhang, and Xintao Wu. 2019. FairGAN+: Achieving fair data generation and classification through generative adversarial nets. In Proceedings of the IEEE International Conference on Big Data (Big Data’19). IEEE, 1401–1406"	58	hort	in-processing	adversarial	generative
376	"Shen Yan, Hsien-te Kao, and Emilio Ferrara. 2020. Fair class balancing: Enhancing model fairness without observing sensitive attributes. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management. 1715–1724"	105	hort	pre-processing	sampling	smote_like
377	"Jenny Yang, Andrew A. S. Soltan, Yang Yang, and David A. Clifton. 2022. Algorithmic fairness and bias mitigation for clinical machine learning: Insights from rapid COVID-19 diagnosis by adversarial learning. medRxiv (2022"	16	hort	in-processing	adversarial	
378	"Mehdi Yazdani-Jahromi, AmirArsalan Rajabi, Aida Tayebi, and Ozlem Ozmen Garibay. 2022. Distraction is all you need for fairness. arXiv preprint arXiv:2203.07593 (2022)."	4	hort	in-processing	adversarial	
379	"I-Cheng Yeh and Che-hui Lien. 2009. The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients. Expert Syst. Applic. 36, 2 (2009), 2473–2480."	1197	hort			
380	"Xiaoxin Yin and Jiawei Han. 2003. CPAR: Classification based on predictive association rules. In Proceedings of the SIAM International Conference on Data Mining. SIAM, 331–335"	1286	hort			
381	Zhe Yu. 2021. Fair balance: Mitigating machine learning bias against multiple protected attributes with data balancing. CoRRabs/2107.08310 (2021).	9	hort	pre-processing	sampling	reweighing
382	"Mikhail Yurochkin, Amanda Bower, and Yuekai Sun. 2020. Training individually fair ML models with sensitive subspace robustness. In Proceedings of the International Conference on Learning Representations. Retrieved from https://openreview.net/forum?id=B1gdkxHFDH"	135	hort	in-processing	adversarial	
383	Mikhail Yurochkin and Yuekai Sun. 2021. SenSeI: Sensitive set invariance for enforcing individual fairness. In Proceedings of the International Conference on Learning Representations.	63	hort	in-processing	regularisation	
384	"Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P. Gummadi. 2017. Fairness beyond disparate treatment & disparate impact: Learning classification without disparate mistreatment. In Proceedings of the 26th International Conference on World Wide Web. 1171–1180."	1428	hort	in-processing	constraints	
385	"Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez-Rodriguez, and Krishna P. Gummadi. 2019. Fairness constraints: A flexible approach for fair classification. J. Mach. Learn. Res. 20, 1 (2019), 2737–2778"	428	hort	in-processing	constraints	
386	"Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, Krishna P. Gummadi, and Adrian Weller. 2017. From parity to preference-based notions of fairness in classification. In Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS’17). Curran Associates Inc., Red Hook, NY, 228238."	274	hort	in-processing	constraints	
387	"Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rogriguez, and Krishna P. Gummadi. 2017. Fairness constraints: mechanisms for fair classification. In Artificial Intelligence and statistics. PMLR, 962–970"	1446	hort	in-processing	constraints	
388	"Meike Zehlike, Philipp Hacker, and Emil Wiedemann. 2020. Matching code and law: Achieving algorithmic fairness with optimal transport. Data Min. Knowl. Discov. 34, 1 (2020), 163–200."	69	hort	pre-processing	representation	optimisation
389	"Vladimiro Zelaya, Paolo Missier, and Dennis Prangle. 2019. Parametrised data sampling for fairness optimisation. KDD XAI (2019)."	15	hort	pre-processing	sampling	sample
390	"Rich Zemel, Yu Wu, Kevin Swersky, Toni Pitassi, and Cynthia Dwork. 2013. Learning fair representations. In Proceedings of the International Conference on Machine Learning. 325–333."	2211	hort	pre-processing	representation	
391	"Xianli Zeng, Edgar Dobriban, and Guang Cheng. 2022. Bayes-optimal classifiers under group fairness. arXiv preprint arXiv:2202.09724(2022"	21	hort	post-processing	output	group_dependent
392	"Xianli Zeng, Edgar Dobriban, and Guang Cheng. 2022. Fair Bayes-optimal classifiers under predictive parity. arXiv preprint arXiv:2205.07182 (2022)."	17	hort	post-processing	output	group_dependent
393	"Brian Hu Zhang, Blake Lemoine, and Margaret Mitchell. 2018. Mitigating unwanted biases with adversarial learning. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. ACM, 335–340"	1619	hort	in-processing	adversarial	lr
394	"Hantian Zhang, Xu Chu, Abolfazl Asudeh, and Shamkant B. Navathe. 2021. OmniFair: A declarative system for model-agnostic group fairness in machine learning. In Proceedings of the International Conference on Management of Data. 2076–2088."	50	hort	in-processing	constraints	
395	Junzhe Zhang and Elias Bareinboim. 2018. Equality of opportunity in classification: A causal approach. In Proceedings of the 32nd International Conference on Neural Information Processing Systems. 3675–3685	107	hort	in-processing	constraints	
396	Junzhe Zhang and Elias Bareinboim. 2018. Fairness in decision-makingThe causal explanation formula. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence.	340	hort	in-processing	constraints	
397	"Jiang Zhang, Ivan Beschastnikh, Sergey Mechtaev, and Abhik Roychoudhury. 2022. Fair decision making via automated repair of decision trees. In Proceedings of the International Workshop on Equitable Data and Technology (FairWare’22)."	6	hort	post-processing	classifier	decision_tree
398	"Jie M. Zhang, Mark Harman, Lei Ma, and Yang Liu. 2020. Machine learning testing: Survey, landscapes and horizons. IEEE Transactions on Software Engineering 48, 1 (2020), 1–36."	963	hort			
399	"Lu Zhang, Yongkai Wu, and Xintao Wu. 2017. A causal framework for discovering and removing direct and indirect discrimination. In Proceedings of the 26th International Joint Conference on Artificial Intelligence. 3929–3935."	217	hort	pre-processing	sampling	generative
400	"Lu Zhang, Yongkai Wu, and Xintao Wu. 2018. Achieving non-discrimination in prediction. In Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI’18). AAAI Press, 30973103"	42	hort	post-processing	output	massaging
401	"Wenbin Zhang, Albert Bifet, Xiangliang Zhang, Jeremy C. Weiss, and Wolfgang Nejdl. 2021. FARF: A fair and adaptive random forests classifier. In Proceedings of the 25th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining (PAKDD’21). 245–256."	61	hort	in-processing	adjusted	downsampling
402	Wenbin Zhang and Eirini Ntoutsi. 2019. FAHT: An adaptive fairness-aware decision tree classifier. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. 1480–1486	118	hort	in-processing	regularisation	decision_tree
403	"Wenbin Zhang, Xuejiao Tang, and Jianwu Wang. 2019. On fairness-aware learning for non-discriminative decision-making. In Proceedings of the International Conference on Data Mining Workshops (ICDMW’19). IEEE, 1072–1079."	27	hort	in-processing	regularisation	decision_tree
404	"Wenbin Zhang and Jeremy C. Weiss. 2021. Fair decision-making under uncertainty. In Proceedings of the IEEE International Conference on Data Mining (ICDM’21). IEEE, 886–895"	49	hort	in-processing	regularisation	decision_tree
405	"Wenbin Zhang and Jeremy C. Weiss. 2022. Longitudinal fairness with censorship. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 36. 12235–12243"	56	hort	in-processing	regularisation	decision_tree
406	"Wenbin Zhang, Jeremy C. Weiss, Shuigeng Zhou, and Toby Walsh. 2022. Fairness amidst non-IID graph data: A literature review. arXiv preprint arXiv:2202.07170 (2022"	33	hort			
407	"Xueru Zhang and Mingyan Liu. 2021. Fairness in learning-based sequential decision algorithms: A survey. In Handbook of Reinforcement Learning and Control. Springer, 525–555"	61	hort			
408	Yue Zhang and Arti Ramesh. 2020. Learning fairness-aware relational structures. arXiv preprint arXiv:2002.09471 (2020	13	hort	in-processing	adjusted	markov
409	"Chen Zhao, Feng Chen, and Bhavani Thuraisingham. 2021. Fairness-aware online meta-learning. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining. 2294–2304."	34	hort	in-processing	constraints	
410	"Chen Zhao, Feng Mi, Xintao Wu, Kai Jiang, Latifur Khan, and Feng Chen. 2022. Adaptive fairness-aware online meta-learning for changing environments. arXiv preprint arXiv:2205.11264 (2022"	20	hort	in-processing	adjusted	
411	"Han Zhao, Amanda Coston, Tameem Adel, and Geoffrey J. Gordon. 2020. Conditional learning of fair representations. In Proceedings of the International Conference on Learning Representations. Retrieved from https://openreview.net/forum?id=Hkekl0NFPr"	124	hort	pre-processing	representation	adversarial
412	Han Zhao and Geoff Gordon. 2019. Inherent tradeoffs in learning fair representations. Adv. Neural Inf. Process. Syst. 32 (2019).	245	hort	in-processing	adversarial	
413	"Jieyu Zhao, Yichao Zhou, Zeyu Li, Wei Wang, and Kai-Wei Chang. 2018. Learning gender-neutral word embeddings. Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’18).4847–4853"	484	hort			
414	"Tianxiang Zhao, Enyan Dai, Kai Shu, and Suhang Wang. 2021. You can still achieve fairness without sensitive attributes: Exploring biases in non-sensitive features. arXiv preprint arXiv:2104.14537 (2021)."	23	hort	in-processing	regularisation	
415	"Tianxiang Zhao, Enyan Dai, Kai Shu, and Suhang Wang. 2022. Towards fair classifiers without sensitive attributes: Exploring biases in related features. In Proceedings of the 15th ACM International Conference on Web Search and Data Mining. 1433–1442."	61	hort	in-processing	regularisation	
416	"Wei Zhu, Haitian Zheng, Haofu Liao, Weijian Li, and Jiebo Luo. 2021. Learning bias-invariant representation by cross-sample mutual information minimization. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 15002–15012"	44	hort	pre-processing	representation	adversarial
417	Indre Žliobaite. 2015. A survey on measuring indirect discrimination in machine learning. arXiv preprint arXiv:1511.00148 (2015	2	hort			
418	"Indre Žliobaite, Faisal Kamiran, and Toon Calders. 2011. Handling conditional discrimination. In Proceedings of the IEEE 11th International Conference on Data Mining. IEEE, 992–1001."	182	hort	pre-processing	sampling	sample